{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df_servers = pd.read_csv('./data/servers.csv')\n",
    "df_servers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_datacenters = pd.read_csv('./data/datacenters.csv')\n",
    "df_datacenters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import zipfile\n",
    "from typing import List\n",
    "def zip_files(file_paths: List[str], output_zip: str):\n",
    "    \"\"\"\n",
    "    Zip multiple files into a single zip file.\n",
    "\n",
    "    :param file_paths: List of file paths to be zipped\n",
    "    :param output_zip: Name of the output zip file\n",
    "    \"\"\"\n",
    "    with zipfile.ZipFile(output_zip, 'w', compression=zipfile.ZIP_DEFLATED, compresslevel=9) as zipf:\n",
    "        for file in file_paths:\n",
    "            if os.path.exists(file):\n",
    "                zipf.write(file, os.path.basename(file))\n",
    "                print(f\"Added {file} to {output_zip}\")\n",
    "            else:\n",
    "                print(f\"Warning: {file} not found and skipped\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from seeds import known_seeds\n",
    "from utils import save_solution\n",
    "from scipy.stats import truncweibull_min\n",
    "from utils import (load_problem_data,\n",
    "                   load_solution)\n",
    "\n",
    "from evaluation import get_actual_demand, evaluation_function\n",
    "\n",
    "import uuid\n",
    "import tqdm\n",
    "import evaluation as evaluation_original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def generate_random_id():\n",
    "    return str(uuid.uuid4())\n",
    "\n",
    "def fill_missing_timestep(df, min_time_step=1, max_time_step=168):\n",
    "    full_range = pd.DataFrame({'time_step': range(min_time_step, max_time_step + 1)})\n",
    "    df_filled = pd.merge(full_range, df, on='time_step', how='left')\n",
    "    numeric_columns = ['high', 'low', 'medium']\n",
    "    df_filled[numeric_columns] = df_filled[numeric_columns].fillna(0)\n",
    "    df_filled['server_generation'] = df_filled['server_generation'].ffill()\n",
    "    df_filled = df_filled.reset_index(drop=True)\n",
    "    return df_filled\n",
    "\n",
    "def calculate_average_real_capacity(df_servers):\n",
    "    list_average_real_capacity = []\n",
    "    for i in range(len(df_servers)):\n",
    "        server_generation = df_servers.loc[i, 'server_generation']\n",
    "        server_capacity = df_servers.loc[i, 'capacity']\n",
    "        average_real_capacity = ((1 - truncweibull_min.rvs(0.3, 0.05, 0.1, size=100000)) * server_capacity).astype(int).mean()\n",
    "        list_average_real_capacity.append(average_real_capacity)\n",
    "    df_servers['average_real_capacity'] = list_average_real_capacity\n",
    "    return df_servers\n",
    "\n",
    "def parse_action_string(action_string):\n",
    "    server_generation, actions, action_params = action_string.split(\"|\")\n",
    "    actions = actions.split(\"-\")\n",
    "    action_params = action_params.split(\"-\")\n",
    "    action_comb = [parse_action_comb_param(server_generation, action, action_param) for action, action_param in zip(actions, action_params)]\n",
    "    action_comb = [action for action in action_comb if action is not None]\n",
    "    return action_comb\n",
    "    \n",
    "def parse_action_comb_param(server_generation, action, action_param):\n",
    "    if action == \"buy\":\n",
    "        datacenter_id, average_U = action_param.split(\",\")\n",
    "        average_U = float(average_U)\n",
    "        return {\"action\": action, \"datacenter_id\": datacenter_id, \"average_U\": average_U, \"server_generation\": server_generation}\n",
    "    elif action == \"dismiss\":\n",
    "        dismiss_age = int(action_param)\n",
    "        return {\"action\": action, \"dismiss_age\": dismiss_age, \"server_generation\": server_generation}\n",
    "    elif action == \"move\":\n",
    "        datacenter_id, average_U, move_age = action_param.split(\",\")\n",
    "        average_U = float(average_U)\n",
    "        move_age = int(move_age)\n",
    "        return {\"action\": action, \"datacenter_id\": datacenter_id, \"average_U\": average_U, \"move_age\": move_age,}\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_servers.sort_values(by=['server_generation', 'capacity'], ascending=[True, True])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "class Solution:\n",
    "\n",
    "    def __init__(self, df_servers, df_data_centers, df_selling_prices, time_steps=[1, 168], verbose=False):\n",
    "        self.df_servers = df_servers.copy()\n",
    "        self.df_servers['server_release_time_start'] = self.df_servers['release_time'].apply(lambda x: int(x.strip('[]').split(',')[0]))\n",
    "        self.df_servers['server_release_time_end'] = self.df_servers['release_time'].apply(lambda x: int(x.strip('[]').split(',')[1]))\n",
    "        \n",
    "        self.df_servers_dict = self.df_servers.set_index('server_generation').to_dict('index')\n",
    "\n",
    "        self.df_sell_prices = df_selling_prices.copy()\n",
    "        self.df_data_centers = df_data_centers.copy()\n",
    "        self.datacenter_ids_to_index = {datacenter_id: i for i, datacenter_id in enumerate(df_data_centers['datacenter_id'].values)}\n",
    "        self.df_datacenters_dict = self.df_data_centers.set_index('datacenter_id').to_dict('index')\n",
    "        self.time_steps = time_steps\n",
    "\n",
    "        self.verbose = verbose\n",
    "    \n",
    "        self.df_servers = calculate_average_real_capacity(self.df_servers)\n",
    "        self.failure_rate = 0.07260491698699582\n",
    "\n",
    "        self.server_generation_unique = self.df_servers['server_generation'].unique()\n",
    "        self.server_generation_to_idx = {server_generation: i for i, server_generation in enumerate(self.server_generation_unique)}\n",
    "\n",
    "        self.sensitivity_unique = ['high', 'medium', 'low']\n",
    "        self.sensitivity_to_idx = {sensitivity: i for i, sensitivity in enumerate(self.sensitivity_unique)}\n",
    "\n",
    "        self.selling_prices = np.zeros((self.df_servers.shape[0], 1, len(self.sensitivity_unique)))\n",
    "        for i, row in self.df_sell_prices.iterrows():\n",
    "            server_idx = self.server_generation_to_idx[row['server_generation']]\n",
    "            sensitivity_idx = self.sensitivity_to_idx[row['latency_sensitivity']]\n",
    "            self.selling_prices[server_idx, 0, sensitivity_idx] = row['selling_price']\n",
    "\n",
    "        self.data_center_max_slots = np.zeros((self.df_data_centers.shape[0], self.time_steps[1]))\n",
    "        for i, row in self.df_data_centers.iterrows():\n",
    "            datacenter_idx = self.datacenter_ids_to_index[row['datacenter_id']]\n",
    "            self.data_center_max_slots[datacenter_idx] = row['slots_capacity']\n",
    "    \n",
    "    def init_solution(self, ):\n",
    "        self.solution = []\n",
    "        \n",
    "        # initialize solution objectives\n",
    "        self.solution_Z = np.zeros((self.df_servers.shape[0], self.time_steps[1], len(self.sensitivity_unique)))\n",
    "        self.solution_L = np.zeros((self.time_steps[1],))\n",
    "        self.solution_R = np.zeros((self.time_steps[1],))\n",
    "        self.solution_C = np.zeros((self.time_steps[1],))\n",
    "        self.solution_num_servers = np.zeros((self.time_steps[1],))\n",
    "        self.data_center_slots = np.zeros((self.df_data_centers.shape[0], self.time_steps[1]))\n",
    "        self.solution_obj = 0\n",
    "\n",
    "    def load_solution(self, df_solution, demand):\n",
    "        self.load_demand(demand)\n",
    "        self.init_solution()\n",
    "\n",
    "        server_id_unique = df_solution['server_id'].unique()\n",
    "\n",
    "        for server_id in tqdm.tqdm(server_id_unique, desc=\"Loading solution\"):\n",
    "            df_solution_server_id = df_solution.loc[df_solution['server_id'] == server_id]\n",
    "            cur_num_servers, cur_Z, cur_L, cur_C, cur_data_center_slots = self.calculate_server_id(df_solution_server_id, append_to_solution=True)\n",
    "\n",
    "            new_num_servers, new_Z, new_L, new_C = self.calculate_new_obj_components(cur_num_servers=cur_num_servers,\n",
    "                                                                                    cur_Z=cur_Z,\n",
    "                                                                                    cur_L=cur_L,\n",
    "                                                                                    cur_C=cur_C)\n",
    "            new_obj, (new_num_servers, new_Z, new_L, new_C, new_U, new_R) = self.calculate_new_obj(new_num_servers=new_num_servers,\n",
    "                                                                                                    new_Z=new_Z,\n",
    "                                                                                                    new_L=new_L,\n",
    "                                                                                                    new_C=new_C)\n",
    "            self.update_new_obj(new_obj=new_obj,\n",
    "                                new_num_servers=new_num_servers,\n",
    "                                new_Z=new_Z,\n",
    "                                new_L=new_L,\n",
    "                                new_C=new_C,\n",
    "                                new_U=new_U,\n",
    "                                new_R=new_R,\n",
    "                                new_data_center_slots=self.data_center_slots + cur_data_center_slots)\n",
    "\n",
    "    def calculate_server_id(self, df_solution_server_id, append_to_solution=False):\n",
    "        df_solution_server_id = df_solution_server_id.sort_values('time_step')\n",
    "        server_id = df_solution_server_id['server_id'].values[0]\n",
    "\n",
    "        server_generation = df_solution_server_id['server_generation'].values[0] \n",
    "        df_cur_server = self.df_servers_dict[server_generation]\n",
    "        server_idx = self.server_generation_to_idx[server_generation]\n",
    "        previous_time_step = 0\n",
    "        previous_datacenter_id = None\n",
    "        dismiss_age = None\n",
    "\n",
    "        cur_num_servers = np.zeros(self.solution_num_servers.shape)\n",
    "        cur_Z = np.zeros(self.solution_Z.shape)\n",
    "        cur_L = np.zeros((self.time_steps[1],))\n",
    "        cur_C = np.zeros((self.time_steps[1],))\n",
    "        cur_data_center_slots = np.zeros(self.data_center_slots.shape)\n",
    "        \n",
    "        for i, row in df_solution_server_id.iterrows():\n",
    "            action = row['action']\n",
    "            datacenter_id = row['datacenter_id']\n",
    "            cur_time_step = row['time_step']\n",
    "\n",
    "            if append_to_solution:\n",
    "                self.solution.append({\n",
    "                    \"time_step\": cur_time_step,\n",
    "                    \"action\": action,\n",
    "                    \"datacenter_id\": datacenter_id,\n",
    "                    \"server_generation\": server_generation,\n",
    "                    \"server_id\": server_id\n",
    "                })\n",
    "            \n",
    "            if action == \"buy\":\n",
    "                buy_time_step = cur_time_step\n",
    "                cur_C[buy_time_step - 1] += df_cur_server['purchase_price']\n",
    "\n",
    "            elif action != \"buy\":\n",
    "                if previous_datacenter_id is None:\n",
    "                    print(df_solution_server_id)\n",
    "                previous_datacenter_idx = self.datacenter_ids_to_index[previous_datacenter_id]\n",
    "                previous_sensitivity = self.df_datacenters_dict[previous_datacenter_id]['latency_sensitivity']\n",
    "                previous_sensitivity_idx = self.sensitivity_to_idx[previous_sensitivity]\n",
    "                previous_datacenter_cost_of_energy = self.df_datacenters_dict[previous_datacenter_id]['cost_of_energy']\n",
    "\n",
    "                cur_data_center_slots[previous_datacenter_idx, previous_time_step - 1:cur_time_step - 1] += df_cur_server['slots_size']\n",
    "                cur_Z[server_idx, previous_time_step - 1:cur_time_step - 1, previous_sensitivity_idx] += df_cur_server['capacity']\n",
    "                cur_C[previous_time_step - 1:cur_time_step - 1] += previous_datacenter_cost_of_energy * df_cur_server['energy_consumption']\n",
    "                if action == \"move\":\n",
    "                    cur_C[cur_time_step - 1] += df_cur_server['cost_of_moving']\n",
    "                elif action == \"dismiss\":\n",
    "                    dismiss_age = cur_time_step - buy_time_step\n",
    "                \n",
    "            previous_time_step = cur_time_step\n",
    "            previous_datacenter_id = datacenter_id\n",
    "\n",
    "        if dismiss_age is None:\n",
    "            dismiss_age = min(df_cur_server['life_expectancy'], self.time_steps[1] - buy_time_step + 1)\n",
    "            cur_time_step = buy_time_step + dismiss_age\n",
    "\n",
    "            previous_datacenter_idx = self.datacenter_ids_to_index[previous_datacenter_id]\n",
    "            previous_sensitivity = self.df_datacenters_dict[previous_datacenter_id]['latency_sensitivity']\n",
    "            previous_sensitivity_idx = self.sensitivity_to_idx[previous_sensitivity]\n",
    "            previous_datacenter_cost_of_energy = self.df_datacenters_dict[previous_datacenter_id]['cost_of_energy']\n",
    "\n",
    "            cur_data_center_slots[previous_datacenter_idx, previous_time_step - 1:cur_time_step - 1] += df_cur_server['slots_size']\n",
    "            cur_Z[server_idx, previous_time_step - 1:cur_time_step - 1, previous_sensitivity_idx] += df_cur_server['capacity']\n",
    "            cur_C[previous_time_step - 1:cur_time_step - 1] += previous_datacenter_cost_of_energy * df_cur_server['energy_consumption']\n",
    "\n",
    "        start_idx = buy_time_step - 1\n",
    "        end_idx = buy_time_step + dismiss_age - 1\n",
    "        cur_L[start_idx:end_idx] = np.arange(1, dismiss_age + 1) / df_cur_server['life_expectancy']\n",
    "        cur_C[start_idx:end_idx] += df_cur_server['average_maintenance_fee'] \\\n",
    "            * (1+1.5 * np.arange(1, dismiss_age + 1) / df_cur_server['life_expectancy'] * np.log2(1.5 * np.arange(1, dismiss_age + 1) / df_cur_server['life_expectancy']))\n",
    "\n",
    "        cur_num_servers[start_idx:end_idx] = 1\n",
    "\n",
    "        return cur_num_servers, cur_Z, cur_L, cur_C, cur_data_center_slots\n",
    "                    \n",
    "\n",
    "    def load_demand(self, demand):\n",
    "        self.df_demand = demand.copy()\n",
    "        actual_demand_by_server_generation = {server_generation: demand[demand['server_generation'] == server_generation].sort_values('time_step') \n",
    "                                            for server_generation in self.server_generation_unique}\n",
    "        for key in actual_demand_by_server_generation:\n",
    "            actual_demand_by_server_generation[key] = fill_missing_timestep(actual_demand_by_server_generation[key])\n",
    "        self.actual_demand_by_server_generation = np.asarray([actual_demand_by_server_generation[server_generation][['high', 'medium', 'low']] \n",
    "                                                              for server_generation in self.server_generation_unique])\n",
    "        # self.actual_demand_by_server_generation shape is (num_server_generations, num_time_steps, num_sensitivity_levels)\n",
    "\n",
    "\n",
    "    def solve(self, demand, df_single_server):\n",
    "        self.df_single_server = df_single_server\n",
    "        self.load_demand(demand)\n",
    "        self.search_actions()\n",
    "        return self.solution\n",
    "    \n",
    "    def post_process_solution(self, merge_gap_sizes=range(10)):\n",
    "        self.merge_server_ids(merge_gap_sizes=merge_gap_sizes)\n",
    "\n",
    "    def remove_nonprofit_server_ids(self, ):\n",
    "        n_removed = 0\n",
    "        total_gain = 0\n",
    "        df_solution = pd.DataFrame(self.solution)\n",
    "        df_solution_server_id = df_solution[df_solution['action'] == 'buy'].copy()\n",
    "        df_solution_server_id = df_solution_server_id.set_index('server_id').join( \\\n",
    "            df_solution[df_solution['action'] == 'move'][['server_id', 'time_step']].set_index('server_id'), \\\n",
    "            rsuffix='_move')\n",
    "        df_solution_server_id = df_solution_server_id.join( \\\n",
    "            df_solution[df_solution['action'] == 'dismiss'][['server_id', 'time_step']].set_index('server_id'), \\\n",
    "            rsuffix='_dismiss')\n",
    "\n",
    "        df_solution_server_id['time_step_dismiss'] = df_solution_server_id['time_step_dismiss'].fillna(df_solution_server_id['time_step'] + 96)\n",
    "        df_solution_server_id['age'] = df_solution_server_id['time_step_dismiss'] - df_solution_server_id['time_step']\n",
    "        df_solution_server_id = df_solution_server_id.sort_values(['age', 'server_generation'], ascending=[True, True],).reset_index(drop=False)\n",
    "\n",
    "        print(\"n servier_id\", df_solution_server_id['server_id'].nunique(), df_solution_server_id.shape[0])\n",
    "\n",
    "        removed_server_ids = set()\n",
    "        server_id_unique = df_solution_server_id['server_id'].unique()\n",
    "        for server_id in tqdm.tqdm(server_id_unique, desc=\"Removing non-profit servers\"):\n",
    "            if server_id in removed_server_ids:\n",
    "                print(f\"BUG: {server_id} already removed\")\n",
    "                import sys\n",
    "                sys.exit(1)\n",
    "                continue\n",
    "            df_solution_server_id_cur = df_solution.loc[df_solution['server_id'] == server_id]\n",
    "            cur_num_servers, cur_Z, cur_L, cur_C, cur_data_center_slots = self.calculate_server_id(df_solution_server_id_cur, append_to_solution=False)\n",
    "            \n",
    "            new_data_center_slots = self.data_center_slots  - cur_data_center_slots\n",
    "            new_num_servers = self.solution_num_servers - cur_num_servers\n",
    "            new_Z = self.solution_Z - cur_Z\n",
    "            new_L = (self.solution_L * self.solution_num_servers - cur_L * cur_num_servers) / np.maximum(new_num_servers, 1)\n",
    "            new_C = self.solution_C - cur_C\n",
    "\n",
    "            new_obj, (new_num_servers, new_Z, new_L, new_C, new_U, new_R) = self.calculate_new_obj(new_num_servers=new_num_servers,\n",
    "                                                                                                new_Z=new_Z,\n",
    "                                                                                                new_L=new_L,\n",
    "                                                                                                new_C=new_C)\n",
    "            \n",
    "            if new_obj <= self.solution_obj:\n",
    "                continue\n",
    "            \n",
    "            \n",
    "            total_gain += new_obj - self.solution_obj\n",
    "            n_removed += 1\n",
    "\n",
    "            self.update_new_obj(new_obj=new_obj,\n",
    "                                new_num_servers=new_num_servers,\n",
    "                                new_Z=new_Z,\n",
    "                                new_L=new_L,\n",
    "                                new_C=new_C,\n",
    "                                new_U=new_U,\n",
    "                                new_R=new_R,\n",
    "                                new_data_center_slots=new_data_center_slots)\n",
    "\n",
    "            df_solution = df_solution.drop(df_solution[df_solution['server_id'] == server_id].index)\n",
    "            removed_server_ids.add(server_id)\n",
    "            \n",
    "        self.solution = df_solution.sort_values(\"time_step\").to_dict('records')\n",
    "        print(f\"Removed {n_removed} servers with total gain {total_gain}\")\n",
    "\n",
    "    def merge_server_ids(self, merge_gap_sizes=range(10)):\n",
    "        df_solution = pd.DataFrame(self.solution)\n",
    "\n",
    "        total_gain = 0\n",
    "        n_merged = 0\n",
    "\n",
    "        # merging\n",
    "        for gap_size in merge_gap_sizes:\n",
    "            for server_generation in self.server_generation_unique:\n",
    "                while True:\n",
    "                    df_solution_server = df_solution.loc[df_solution['server_generation'] == server_generation]\n",
    "                    df_solution_server_id = df_solution_server[df_solution_server['action'] == 'buy']\n",
    "                    df_solution_server_id = df_solution_server_id.set_index('server_id').join( \\\n",
    "                        df_solution_server[df_solution_server['action'] == 'move'][['server_id', 'time_step']].set_index('server_id'), \\\n",
    "                        rsuffix='_move')\n",
    "                    df_solution_server_id = df_solution_server_id.join( \\\n",
    "                        df_solution_server[df_solution_server['action'] == 'dismiss'][['server_id', 'time_step']].set_index('server_id'), \\\n",
    "                        rsuffix='_dismiss')\n",
    "\n",
    "                    # if time_step_dismiss is None then time_step_dismiss = time_step + 96\n",
    "                    df_solution_server_id['time_step_dismiss'] = df_solution_server_id['time_step_dismiss'].fillna(df_solution_server_id['time_step'] + 96)\n",
    "                    df_solution_server_id['age'] = df_solution_server_id['time_step_dismiss'] - df_solution_server_id['time_step']\n",
    "                    df_solution_server_id_with_dismiss = df_solution_server_id[df_solution_server_id['age'] < 96].reset_index(drop=False)\n",
    "\n",
    "                    # see if any server is dismissed before other servers are bought, every time_step_dismiss should be greater than time_step\n",
    "                    cross_diff = df_solution_server_id_with_dismiss['time_step'].values - df_solution_server_id_with_dismiss['time_step_dismiss'].values.reshape(-1, 1)\n",
    "\n",
    "                    indexes_1, indexes_2 = np.where(np.abs(cross_diff) <= gap_size)\n",
    "                    # indexes_1, indexes_2 = np.where(np.logical_and(cross_diff >= -gap_size, cross_diff <=  0))\n",
    "                    # indexes_1, indexes_2 = np.where(np.logical_and(cross_diff <= gap_size, cross_diff >=  0))\n",
    "                    removed_indexes_2 = set()\n",
    "                    changed = False\n",
    "                    for idx_1 in np.unique(indexes_1):\n",
    "                        idx_1 = idx_1.item()\n",
    "                        if idx_1 in removed_indexes_2:\n",
    "                            continue\n",
    "\n",
    "                        cur_age = df_solution_server_id_with_dismiss['age'].values[idx_1]\n",
    "                        cur_indexes_2 = indexes_2[indexes_1 == idx_1]\n",
    "\n",
    "                        # remove removed_indexes_2 from cur_indexes_2\n",
    "                        cur_indexes_2 = np.array([idx for idx in cur_indexes_2 if idx not in removed_indexes_2 and idx != idx_1])\n",
    "                        if len(cur_indexes_2) == 0:\n",
    "                            continue\n",
    "\n",
    "                        # check age\n",
    "                        cur_age_2 = df_solution_server_id_with_dismiss['age'].values[cur_indexes_2]\n",
    "                        cross_diff_2 = cross_diff[idx_1, cur_indexes_2]\n",
    "                        cur_indexes_2 = cur_indexes_2[cur_age + cur_age_2 + cross_diff_2 <= 96]\n",
    "                        if len(cur_indexes_2) == 0:\n",
    "                            continue\n",
    "\n",
    "                        cur_indexes_2_argsort = np.argsort(df_solution_server_id_with_dismiss['age'].values[cur_indexes_2])[::-1]\n",
    "                        cur_indexes_2 = cur_indexes_2[cur_indexes_2_argsort]\n",
    "                        for idx_2 in cur_indexes_2[:1]:\n",
    "\n",
    "                            server_id_1 = df_solution_server_id_with_dismiss['server_id'].values[idx_1]\n",
    "                            server_id_2 = df_solution_server_id_with_dismiss['server_id'].values[idx_2]\n",
    "\n",
    "                            df_solution_server_id_1 = df_solution_server.loc[df_solution_server['server_id'] \n",
    "                                                                                             == server_id_1].sort_values('time_step')\n",
    "                            df_solution_server_id_2 = df_solution_server.loc[df_solution_server['server_id'] \n",
    "                                                                                             == server_id_2].sort_values('time_step')\n",
    "\n",
    "                            \n",
    "                            # remove calculations for server_id_1 and server_id_2\n",
    "                            cur_num_servers_1, cur_Z_1, cur_L_1, cur_C_1, cur_data_center_slots_1 = self.calculate_server_id(df_solution_server_id_1, append_to_solution=False)\n",
    "                            cur_num_servers_2, cur_Z_2, cur_L_2, cur_C_2, cur_data_center_slots_2 = self.calculate_server_id(df_solution_server_id_2, append_to_solution=False)\n",
    "\n",
    "                            df_solution_new_server_id = pd.concat([df_solution_server_id_1, df_solution_server_id_2]).sort_values('time_step')\n",
    "\n",
    "                            # drop dismiss of the server_id_1\n",
    "                            df_solution_new_server_id = df_solution_new_server_id.drop(df_solution_new_server_id[np.logical_and(df_solution_new_server_id['action'] == 'dismiss',\n",
    "                                                                                                                            df_solution_new_server_id['server_id'] == server_id_1)].index)\n",
    "                            \n",
    "                            # change buy of server_id_2 to move\n",
    "                            df_solution_new_server_id.loc[np.logical_and(df_solution_new_server_id['action'] == 'buy',\n",
    "                                                                        df_solution_new_server_id['server_id'] == server_id_2), 'action'] = 'move'\n",
    "                            \n",
    "                            df_solution_new_server_id['server_id'] = server_id_1\n",
    "\n",
    "                            cur_num_servers_new, cur_Z_new, cur_L_new, cur_C_new, cur_data_center_slots_new = self.calculate_server_id(df_solution_new_server_id, append_to_solution=False)\n",
    "\n",
    "                            new_data_center_slots = self.data_center_slots + cur_data_center_slots_new - cur_data_center_slots_1 - cur_data_center_slots_2 \n",
    "                            if np.any(self.data_center_max_slots < new_data_center_slots):\n",
    "                                continue\n",
    "\n",
    "                            new_num_servers = self.solution_num_servers + cur_num_servers_new - cur_num_servers_1 - cur_num_servers_2\n",
    "                            new_Z = self.solution_Z + cur_Z_new - cur_Z_1 - cur_Z_2\n",
    "                            new_L = (self.solution_L * self.solution_num_servers + cur_L_new * cur_num_servers_new - cur_L_1 * cur_num_servers_1 - cur_L_2 * cur_num_servers_2) / np.maximum(new_num_servers, 1)\n",
    "                            new_C = self.solution_C + cur_C_new - cur_C_1 - cur_C_2\n",
    "\n",
    "                            new_obj, (new_num_servers, new_Z, new_L, new_C, new_U, new_R) = self.calculate_new_obj(new_num_servers=new_num_servers,\n",
    "                                                                                                                new_Z=new_Z,\n",
    "                                                                                                                new_L=new_L,\n",
    "                                                                                                                new_C=new_C)\n",
    "\n",
    "                            if new_obj <= self.solution_obj:\n",
    "                                continue\n",
    "\n",
    "                            total_gain += new_obj - self.solution_obj\n",
    "                            n_merged += 1\n",
    "                            \n",
    "                            self.update_new_obj(new_obj=new_obj,\n",
    "                                                new_num_servers=new_num_servers,\n",
    "                                                new_Z=new_Z,\n",
    "                                                new_L=new_L,\n",
    "                                                new_C=new_C,\n",
    "                                                new_U=new_U,\n",
    "                                                new_R=new_R,\n",
    "                                                new_data_center_slots=new_data_center_slots)\n",
    "                            \n",
    "                            df_solution = df_solution.drop(df_solution[np.logical_or(df_solution['server_id'] == server_id_1, df_solution['server_id'] == server_id_2)].index)\n",
    "                            df_solution = pd.concat([df_solution, df_solution_new_server_id])\n",
    "\n",
    "                            removed_indexes_2.add(idx_1)\n",
    "                            removed_indexes_2.add(idx_2)\n",
    "                            changed = True\n",
    "                            break\n",
    "                    if not changed:\n",
    "                        break\n",
    "        print(f\"Merged {n_merged} servers with total gain {total_gain}\")\n",
    "        \n",
    "        self.solution = df_solution.sort_values(\"time_step\").to_dict('records')\n",
    "\n",
    "    \n",
    "    def search_actions(self,):\n",
    "\n",
    "        for action_string in tqdm.tqdm(self.df_single_server['action_string'].values, desc=\"Searching actions\"):\n",
    "            if \"|buy-dismiss|\" in action_string:\n",
    "                self.search_buy_dismiss_combination(action_string)\n",
    "            elif \"|buy-move-dismiss|\" in action_string:\n",
    "                self.search_buy_move_dismiss_combination(action_string)\n",
    "\n",
    "    def search_buy_move_dismiss_combination(self, action_string):\n",
    "        action_comb = parse_action_string(action_string)\n",
    "\n",
    "        server_generation = action_comb[0]['server_generation']\n",
    "\n",
    "        datacenter_id_1 = action_comb[0]['datacenter_id']\n",
    "        datacenter_id_2 = action_comb[1]['datacenter_id']\n",
    "\n",
    "        move_age = action_comb[1]['move_age']\n",
    "        dissmiss_age = action_comb[2]['dismiss_age']\n",
    "\n",
    "\n",
    "        df_cur_server = self.df_servers_dict[server_generation]\n",
    "        df_datacenter_1 = self.df_datacenters_dict[datacenter_id_1]\n",
    "        df_datacenter_2 = self.df_datacenters_dict[datacenter_id_2]\n",
    "\n",
    "        utilization_threshold_1 = action_comb[0]['average_U']\n",
    "        utilization_threshold_2 = action_comb[1]['average_U']\n",
    "\n",
    "        sensitivity_1 = df_datacenter_1['latency_sensitivity']\n",
    "        sensitivity_2 = df_datacenter_2['latency_sensitivity']\n",
    "\n",
    "        datacenter_cost_of_energy_1 = df_datacenter_1['cost_of_energy']\n",
    "        datacenter_cost_of_energy_2 = df_datacenter_2['cost_of_energy']\n",
    "\n",
    "        server_capacity = df_cur_server['capacity']\n",
    "        server_energy_consumption = df_cur_server['energy_consumption']\n",
    "        server_life_expectancy = df_cur_server['life_expectancy']\n",
    "        server_average_maintenance_fee = df_cur_server['average_maintenance_fee']\n",
    "        server_purchase_price = df_cur_server['purchase_price']\n",
    "        server_cost_of_moving = df_cur_server['cost_of_moving']\n",
    "        server_slots_size = df_cur_server['slots_size']\n",
    "        server_release_time_start = df_cur_server['server_release_time_start']\n",
    "        server_release_time_end = df_cur_server['server_release_time_end']\n",
    "\n",
    "        datacenter_idx_1 = self.datacenter_ids_to_index[datacenter_id_1]\n",
    "        datacenter_idx_2 = self.datacenter_ids_to_index[datacenter_id_2]\n",
    "        server_idx = self.server_generation_to_idx[server_generation]\n",
    "        sensitivity_idx_1 = self.sensitivity_to_idx[sensitivity_1]\n",
    "        sensitivity_idx_2 = self.sensitivity_to_idx[sensitivity_2]\n",
    "\n",
    "        demand_arr_1 = self.actual_demand_by_server_generation[server_idx, :, self.sensitivity_to_idx[sensitivity_1]]\n",
    "        demand_arr_2 = self.actual_demand_by_server_generation[server_idx, :, self.sensitivity_to_idx[sensitivity_2]]\n",
    "        total_buys = 0\n",
    "        for buy_time_step in range(server_release_time_start, server_release_time_end + 1):\n",
    "            start_idx_1 = buy_time_step - 1\n",
    "            end_idx_1 = buy_time_step + move_age - 1\n",
    "            start_idx_2 = buy_time_step + move_age - 1\n",
    "            end_idx_2 = buy_time_step + dissmiss_age - 1\n",
    "\n",
    "            demand_subarr_1 = demand_arr_1[start_idx_1:end_idx_1]\n",
    "            demand_subarr_2 = demand_arr_2[start_idx_2:end_idx_2]\n",
    "            if demand_subarr_1.shape[0] < move_age or demand_subarr_1.shape[0] + demand_subarr_2.shape[0] < dissmiss_age:\n",
    "                break\n",
    "\n",
    "            while True:\n",
    "\n",
    "                # check utilization condition for datacenter 1\n",
    "                demand_subarr_1_capped = np.minimum(demand_subarr_1, server_capacity)\n",
    "                average_utilization_1 = np.mean(demand_subarr_1_capped/ server_capacity)\n",
    "                if average_utilization_1 < utilization_threshold_1:\n",
    "                    break\n",
    "\n",
    "                # check utilization condition for datacenter 2\n",
    "                demand_subarr_2_capped = np.minimum(demand_subarr_2, server_capacity)\n",
    "                average_utilization_2 = np.mean(demand_subarr_2_capped/ server_capacity)\n",
    "                if average_utilization_2 < utilization_threshold_2:\n",
    "                    break\n",
    "\n",
    "                # check data center slots\n",
    "                new_data_center_slots = np.copy(self.data_center_slots)\n",
    "                new_data_center_slots[datacenter_idx_1, start_idx_1:end_idx_1] += server_slots_size\n",
    "                new_data_center_slots[datacenter_idx_2, start_idx_2:end_idx_2] += server_slots_size\n",
    "                if np.any(self.data_center_max_slots < new_data_center_slots):\n",
    "                    break\n",
    "\n",
    "                # check if adding the server is beneficial by calculating the objective function\n",
    "\n",
    "                ### calculate for the new server\n",
    "                cur_Z = np.zeros(self.solution_Z.shape)\n",
    "                cur_Z[server_idx, start_idx_1:end_idx_1, sensitivity_idx_1] = server_capacity\n",
    "                cur_Z[server_idx, start_idx_2:end_idx_2, sensitivity_idx_2] = server_capacity\n",
    "\n",
    "                cur_L = np.zeros(self.solution_L.shape)\n",
    "                cur_L[start_idx_1:end_idx_2] = np.arange(1, dissmiss_age + 1) / server_life_expectancy\n",
    "\n",
    "                cur_E = np.zeros(self.solution_L.shape)\n",
    "                cur_E[start_idx_1:end_idx_2] = datacenter_cost_of_energy_1 * server_energy_consumption\n",
    "                cur_E[start_idx_2:end_idx_2] = datacenter_cost_of_energy_2 * server_energy_consumption\n",
    "\n",
    "                cur_alpha = np.zeros(self.solution_L.shape)\n",
    "                cur_alpha[start_idx_1:end_idx_2] = server_average_maintenance_fee \\\n",
    "                    * (1+1.5 * np.arange(1, dissmiss_age + 1) / server_life_expectancy * np.log2(1.5 * np.arange(1, dissmiss_age + 1) / server_life_expectancy))\n",
    "                cur_C = cur_E + cur_alpha\n",
    "                cur_C[start_idx_1] += server_purchase_price\n",
    "                cur_C[start_idx_2] += server_cost_of_moving\n",
    "\n",
    "                cur_num_servers = np.zeros(self.solution_L.shape)\n",
    "                cur_num_servers[start_idx_1:end_idx_2] = 1\n",
    "\n",
    "                new_num_servers, new_Z, new_L, new_C = self.calculate_new_obj_components(cur_num_servers=cur_num_servers,\n",
    "                                                                                        cur_Z=cur_Z,\n",
    "                                                                                        cur_L=cur_L,\n",
    "                                                                                        cur_C=cur_C)\n",
    "                new_obj, (new_num_servers, new_Z, new_L, new_C, new_U, new_R) = self.calculate_new_obj(new_num_servers=new_num_servers,\n",
    "                                                                                                    new_Z=new_Z,\n",
    "                                                                                                    new_L=new_L,\n",
    "                                                                                                    new_C=new_C)\n",
    "                if new_obj <= self.solution_obj:\n",
    "                    break\n",
    "                \n",
    "                self.update_new_obj(new_obj=new_obj,\n",
    "                                    new_num_servers=new_num_servers,\n",
    "                                    new_Z=new_Z,\n",
    "                                    new_L=new_L,\n",
    "                                    new_C=new_C,\n",
    "                                    new_U=new_U,\n",
    "                                    new_R=new_R,\n",
    "                                    new_data_center_slots=new_data_center_slots)\n",
    "\n",
    "                self.add_buy_move_dismiss_action(datacenter_id_1=datacenter_id_1,\n",
    "                                                    datacenter_id_2=datacenter_id_2,\n",
    "                                                    server_generation=server_generation,\n",
    "                                                    move_age=move_age,\n",
    "                                                    dismiss_age=dissmiss_age,\n",
    "                                                    time_step=buy_time_step)\n",
    "                total_buys += 1\n",
    "        if self.verbose and total_buys > 0:\n",
    "            print(f\"Bought {total_buys} servers with action string {action_string}\")\n",
    "\n",
    "        \n",
    "    def search_buy_dismiss_combination(self, action_string):\n",
    "        action_comb = parse_action_string(action_string)\n",
    "\n",
    "        server_generation = action_comb[0]['server_generation']\n",
    "        datacenter_id = action_comb[0]['datacenter_id']\n",
    "\n",
    "        df_cur_server = self.df_servers_dict[server_generation]\n",
    "        df_datacenter = self.df_datacenters_dict[datacenter_id]\n",
    "\n",
    "        utilization_threshold = action_comb[0]['average_U']\n",
    "\n",
    "        sensitivity = df_datacenter['latency_sensitivity']\n",
    "        datacenter_cost_of_energy = df_datacenter['cost_of_energy']\n",
    "\n",
    "        server_capacity = df_cur_server['capacity']\n",
    "        server_energy_consumption = df_cur_server['energy_consumption']\n",
    "        server_life_expectancy = df_cur_server['life_expectancy']\n",
    "        server_average_maintenance_fee = df_cur_server['average_maintenance_fee']\n",
    "        server_purchase_price = df_cur_server['purchase_price']\n",
    "        server_slots_size = df_cur_server['slots_size']\n",
    "        server_release_time_start = df_cur_server['server_release_time_start']\n",
    "        server_release_time_end = df_cur_server['server_release_time_end']\n",
    "        dissmiss_age = action_comb[1]['dismiss_age']\n",
    "\n",
    "        datacenter_idx = self.datacenter_ids_to_index[datacenter_id]\n",
    "        server_idx = self.server_generation_to_idx[server_generation]\n",
    "        sensitivity_idx = self.sensitivity_to_idx[sensitivity]\n",
    "        demand_arr = self.actual_demand_by_server_generation[server_idx, :, sensitivity_idx]\n",
    "        total_buys = 0\n",
    "        for buy_time_step in range(server_release_time_start, server_release_time_end + 1):\n",
    "            start_idx = buy_time_step - 1\n",
    "            end_idx = buy_time_step + dissmiss_age - 1\n",
    "            demand_subarr = demand_arr[start_idx:end_idx]\n",
    "            if demand_subarr.shape[0] < dissmiss_age:\n",
    "                break\n",
    "\n",
    "            while True:\n",
    "                # check utilization condition\n",
    "                demand_subarr_capped = np.minimum(demand_subarr, server_capacity)\n",
    "                average_utilization = np.mean(demand_subarr_capped/ server_capacity)\n",
    "                if average_utilization < utilization_threshold:\n",
    "                    break\n",
    "\n",
    "                # check data center slots\n",
    "                new_data_center_slots = np.copy(self.data_center_slots)\n",
    "                new_data_center_slots[datacenter_idx, start_idx:end_idx] += server_slots_size\n",
    "\n",
    "                if np.any(self.data_center_max_slots < new_data_center_slots):\n",
    "                    break\n",
    "                \n",
    "                # check if adding the server is beneficial by calculating the objective function\n",
    "                cur_Z = np.zeros(self.solution_Z.shape)\n",
    "                cur_Z[server_idx, start_idx:end_idx, sensitivity_idx] = server_capacity\n",
    "                \n",
    "                cur_L = np.zeros((self.time_steps[1],))\n",
    "                cur_L[start_idx:end_idx] = np.arange(1, dissmiss_age + 1) / server_life_expectancy\n",
    "\n",
    "                cur_E = np.zeros((self.time_steps[1],))\n",
    "                cur_E[start_idx:end_idx] = datacenter_cost_of_energy * server_energy_consumption\n",
    "\n",
    "                cur_alpha = np.zeros((self.time_steps[1],))\n",
    "                cur_alpha[start_idx:end_idx] = server_average_maintenance_fee \\\n",
    "                    * (1+1.5 * np.arange(1, dissmiss_age + 1) / server_life_expectancy * np.log2(1.5 * np.arange(1, dissmiss_age + 1) / server_life_expectancy))\n",
    "                cur_C = cur_E + cur_alpha\n",
    "                cur_C[start_idx] += server_purchase_price\n",
    "\n",
    "                cur_num_servers = np.zeros((self.time_steps[1],))\n",
    "                cur_num_servers[start_idx:end_idx] = 1\n",
    "\n",
    "\n",
    "                new_num_servers, new_Z, new_L, new_C = self.calculate_new_obj_components(cur_num_servers=cur_num_servers,\n",
    "                                                                                        cur_Z=cur_Z,\n",
    "                                                                                        cur_L=cur_L,\n",
    "                                                                                        cur_C=cur_C)\n",
    "                new_obj, (new_num_servers, new_Z, new_L, new_C, new_U, new_R) = self.calculate_new_obj(new_num_servers=new_num_servers,\n",
    "                                                                                                       new_Z=new_Z,\n",
    "                                                                                                       new_L=new_L,\n",
    "                                                                                                       new_C=new_C)\n",
    "                if new_obj <= self.solution_obj:\n",
    "                    break\n",
    "\n",
    "                self.update_new_obj(new_obj=new_obj,\n",
    "                                    new_num_servers=new_num_servers,\n",
    "                                    new_Z=new_Z,\n",
    "                                    new_L=new_L,\n",
    "                                    new_C=new_C,\n",
    "                                    new_U=new_U,\n",
    "                                    new_R=new_R,\n",
    "                                    new_data_center_slots=new_data_center_slots)\n",
    "                \n",
    "                self.add_buy_dismiss_action(datacenter_id=datacenter_id, \n",
    "                                        server_generation=server_generation, \n",
    "                                        dismiss_age=dissmiss_age, \n",
    "                                        time_step=buy_time_step)\n",
    "                total_buys += 1\n",
    "                    \n",
    "        if self.verbose and total_buys > 0:\n",
    "            print(f\"Bought {total_buys} servers with action string {action_string}\")\n",
    "\n",
    "    def calculate_new_obj_components(self, cur_num_servers, cur_Z, cur_L, cur_C):\n",
    "        new_num_servers = self.solution_num_servers + cur_num_servers\n",
    "        new_Z = self.solution_Z + cur_Z\n",
    "        new_L = (self.solution_L * self.solution_num_servers + cur_L * cur_num_servers) / np.maximum(new_num_servers, 1)\n",
    "        new_C = self.solution_C + cur_C\n",
    "        return new_num_servers, new_Z, new_L, new_C\n",
    "\n",
    "    def calculate_new_obj(self, new_num_servers, new_Z, new_L, new_C):\n",
    "\n",
    "        new_Z_failure = (new_Z * (1-self.failure_rate)).astype(int)\n",
    "        new_Z_failure_demand = np.minimum(new_Z_failure, self.actual_demand_by_server_generation)\n",
    "        new_U = np.where(new_Z_failure > 0.5,\n",
    "                            new_Z_failure_demand / np.maximum(1.0, new_Z_failure),\n",
    "                            np.nan)\n",
    "        new_U = np.nanmean(new_U, axis=(0, 2))\n",
    "        new_U = np.nan_to_num(new_U, nan=0)\n",
    "\n",
    "        new_R = new_Z_failure_demand * self.selling_prices\n",
    "        new_R = np.nansum(new_R, axis=(0, 2))\n",
    "\n",
    "        new_obj = new_U * new_L * (new_R - new_C)\n",
    "        new_obj = np.nansum(new_obj)\n",
    "\n",
    "        return new_obj, (new_num_servers, new_Z, new_L, new_C, new_U, new_R)\n",
    "    \n",
    "    def update_new_obj(self, new_obj, new_num_servers, new_Z, new_L, new_C, new_U, new_R, new_data_center_slots):\n",
    "        self.solution_obj = new_obj\n",
    "        self.solution_Z = new_Z\n",
    "        self.solution_L = new_L\n",
    "        self.solution_C = new_C\n",
    "        self.solution_R = new_R\n",
    "        self.solution_U = new_U\n",
    "        self.solution_num_servers = new_num_servers\n",
    "        self.data_center_slots = new_data_center_slots\n",
    "\n",
    "\n",
    "\n",
    "    def add_buy_move_dismiss_action(self, datacenter_id_1, datacenter_id_2, server_generation, move_age, dismiss_age, time_step):\n",
    "        server_life_expectancy = self.df_servers_dict[server_generation]['life_expectancy']\n",
    "\n",
    "        server_id = generate_random_id()\n",
    "        self.solution.append({\n",
    "            \"time_step\": time_step,\n",
    "            \"action\": \"buy\",\n",
    "            \"datacenter_id\": datacenter_id_1,\n",
    "            \"server_generation\": server_generation,\n",
    "            \"server_id\": server_id\n",
    "        })\n",
    "\n",
    "        if time_step + move_age <= self.time_steps[1]:\n",
    "            self.solution.append({\n",
    "                \"time_step\": time_step + move_age,\n",
    "                \"action\": \"move\",\n",
    "                \"datacenter_id\": datacenter_id_2,\n",
    "                \"server_generation\": server_generation,\n",
    "                \"server_id\": server_id\n",
    "            })\n",
    "\n",
    "        if dismiss_age < server_life_expectancy and time_step + dismiss_age <= self.time_steps[1]:\n",
    "            self.solution.append({\n",
    "                \"time_step\": time_step + dismiss_age,\n",
    "                \"action\": \"dismiss\",\n",
    "                \"datacenter_id\": datacenter_id_2,\n",
    "                \"server_generation\": server_generation,\n",
    "                \"server_id\": server_id\n",
    "            })\n",
    "\n",
    "    def add_buy_dismiss_action(self, datacenter_id, server_generation, dismiss_age, time_step):\n",
    "        server_life_expectancy = self.df_servers_dict[server_generation]['life_expectancy']\n",
    "        \n",
    "        server_id = generate_random_id()\n",
    "        self.solution.append({\n",
    "            \"time_step\": time_step,\n",
    "            \"action\": \"buy\",\n",
    "            \"datacenter_id\": datacenter_id,\n",
    "            \"server_generation\": server_generation,\n",
    "            \"server_id\": server_id\n",
    "        })\n",
    "        if dismiss_age < server_life_expectancy and time_step + dismiss_age <= self.time_steps[1]:\n",
    "            self.solution.append({\n",
    "                \"time_step\": time_step + dismiss_age,\n",
    "                \"action\": \"dismiss\",\n",
    "                \"datacenter_id\": datacenter_id,\n",
    "                \"server_generation\": server_generation,\n",
    "                \"server_id\": server_id\n",
    "            })\n",
    "\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "\n",
    "def get_my_solution(d, df_single_server, verbose=False, failure_rate_r=0.0):\n",
    "    _, df_datacenters, df_servers, df_selling_prices = load_problem_data()\n",
    "    solution = Solution(df_servers=df_servers, \n",
    "                        df_data_centers=df_datacenters, \n",
    "                        df_selling_prices=df_selling_prices,\n",
    "                        verbose=verbose)\n",
    "    solution.failure_rate = 0.07260491698699582 * failure_rate_r\n",
    "    solution.init_solution()\n",
    "    best_obj = 0\n",
    "    best_solution = None\n",
    "    for _ in range(2):\n",
    "        solution.solve(d, df_single_server=df_single_server)\n",
    "        if solution.solution_obj > best_obj:\n",
    "            print(f\"New best solution: {solution.solution_obj}\")\n",
    "            best_obj = solution.solution_obj\n",
    "            best_solution = deepcopy(solution)\n",
    "            save_solution(best_solution.solution, \"df_BUG.csv\")\n",
    "        else:\n",
    "            break\n",
    "        solution.merge_server_ids(merge_gap_sizes=range(12))\n",
    "        if solution.solution_obj > best_obj:\n",
    "            print(f\"New best solution: {solution.solution_obj}\")\n",
    "            best_obj = solution.solution_obj\n",
    "            best_solution = deepcopy(solution)\n",
    "            save_solution(best_solution.solution, \"df_BUG.csv\")\n",
    "        else:\n",
    "            break\n",
    "        solution.remove_nonprofit_server_ids()\n",
    "        if solution.solution_obj > best_obj:\n",
    "            print(f\"New best solution: {solution.solution_obj}\")\n",
    "            best_obj = solution.solution_obj\n",
    "            best_solution = deepcopy(solution)\n",
    "            save_solution(best_solution.solution, \"df_BUG.csv\")\n",
    "        else:\n",
    "            break\n",
    "    return best_solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# solving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "demand, datacenters, servers, selling_prices = load_problem_data()\n",
    "\n",
    "\n",
    "df_single_server_v2 = pd.read_csv(\"df_single_server_results_v6_buydismiss_UP.csv\")\n",
    "df_single_server_v3 = pd.read_csv(\"df_single_server_results_v6_buymovedismiss_UP.csv\")\n",
    "list_df_v3_filtered = []\n",
    "for server_generataion in df_single_server_v3['server_generation'].unique():\n",
    "    df_server_generation = df_single_server_v3[df_single_server_v3['server_generation'] == server_generataion]\n",
    "    df_server_generation = df_server_generation.iloc[:int(len(df_server_generation) * 0.2)]\n",
    "    list_df_v3_filtered.append(df_server_generation)\n",
    "df_single_server_v3_filtered = pd.concat(list_df_v3_filtered)\n",
    "df_single_server_v3_filtered = df_single_server_v3_filtered.sort_values('score_per_slot', ascending=False).reset_index(drop=True)\n",
    "df_single_server = pd.concat([df_single_server_v2, df_single_server_v3_filtered])\n",
    "\n",
    "\n",
    "total_score = 0\n",
    "\n",
    "list_solution = []\n",
    "list_real_scores = []\n",
    "seeds =  [3329, 4201, 8761, 2311, 2663, 4507, 6247, 2281, 4363, 5693]\n",
    "for seed in seeds[:1]:\n",
    "    np.random.seed(seed)\n",
    "    actual_demand = get_actual_demand(demand)\n",
    "\n",
    "    solution = get_my_solution(actual_demand, \n",
    "                            df_single_server=df_single_server,\n",
    "                            verbose=False,\n",
    "                            failure_rate_r=0.2)\n",
    "    # save_solution(solution.solution, f\"./output_test/{seed}.json\")\n",
    "    df_solution = pd.DataFrame(solution.solution)\n",
    "\n",
    "    score = evaluation_original.evaluation_function(df_solution,\n",
    "                                demand,\n",
    "                                datacenters,\n",
    "                                servers,\n",
    "                                selling_prices,\n",
    "                                seed=seed,\n",
    "                                verbose=False)\n",
    "    print(f\"Seed: {seed}, Score: {score}, solution obj {solution.solution_obj}\")\n",
    "    total_score += score\n",
    "\n",
    "    list_solution.append(solution)\n",
    "    list_real_scores.append(score)\n",
    "\n",
    "print(f\"Total score: {total_score}\")\n",
    "\n",
    "\n",
    "# solution_files = [f\"./output_test/{seed}.json\" for seed in seeds]\n",
    "# zip_files(solution_files, \"./solution_v9v3_test.zip\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "huawei-2024-venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
