{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "import logging\n",
    "import time\n",
    "import random\n",
    "from logging.handlers import QueueHandler, QueueListener\n",
    "from multiprocessing import Queue\n",
    "\n",
    "# set file logging\n",
    "file_handler = logging.FileHandler('solution_13v2.log', mode='a')\n",
    "file_handler.setFormatter(logging.Formatter('%(asctime)s - %(processName)s - %(message)s'))\n",
    "\n",
    "root_logger = logging.getLogger()\n",
    "root_logger.setLevel(logging.INFO)\n",
    "root_logger.addHandler(file_handler)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>server_generation</th>\n",
       "      <th>server_type</th>\n",
       "      <th>release_time</th>\n",
       "      <th>purchase_price</th>\n",
       "      <th>slots_size</th>\n",
       "      <th>energy_consumption</th>\n",
       "      <th>capacity</th>\n",
       "      <th>life_expectancy</th>\n",
       "      <th>cost_of_moving</th>\n",
       "      <th>average_maintenance_fee</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CPU.S1</td>\n",
       "      <td>CPU</td>\n",
       "      <td>[1,60]</td>\n",
       "      <td>15000</td>\n",
       "      <td>2</td>\n",
       "      <td>400</td>\n",
       "      <td>60</td>\n",
       "      <td>96</td>\n",
       "      <td>1000</td>\n",
       "      <td>288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CPU.S2</td>\n",
       "      <td>CPU</td>\n",
       "      <td>[37,96]</td>\n",
       "      <td>16000</td>\n",
       "      <td>2</td>\n",
       "      <td>460</td>\n",
       "      <td>75</td>\n",
       "      <td>96</td>\n",
       "      <td>1000</td>\n",
       "      <td>308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CPU.S3</td>\n",
       "      <td>CPU</td>\n",
       "      <td>[73,132]</td>\n",
       "      <td>19500</td>\n",
       "      <td>2</td>\n",
       "      <td>800</td>\n",
       "      <td>120</td>\n",
       "      <td>96</td>\n",
       "      <td>1000</td>\n",
       "      <td>375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CPU.S4</td>\n",
       "      <td>CPU</td>\n",
       "      <td>[109,168]</td>\n",
       "      <td>22000</td>\n",
       "      <td>2</td>\n",
       "      <td>920</td>\n",
       "      <td>160</td>\n",
       "      <td>96</td>\n",
       "      <td>1000</td>\n",
       "      <td>423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GPU.S1</td>\n",
       "      <td>GPU</td>\n",
       "      <td>[1,72]</td>\n",
       "      <td>120000</td>\n",
       "      <td>4</td>\n",
       "      <td>3000</td>\n",
       "      <td>8</td>\n",
       "      <td>96</td>\n",
       "      <td>1000</td>\n",
       "      <td>2310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>GPU.S2</td>\n",
       "      <td>GPU</td>\n",
       "      <td>[49,120]</td>\n",
       "      <td>140000</td>\n",
       "      <td>4</td>\n",
       "      <td>3000</td>\n",
       "      <td>8</td>\n",
       "      <td>96</td>\n",
       "      <td>1000</td>\n",
       "      <td>2695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>GPU.S3</td>\n",
       "      <td>GPU</td>\n",
       "      <td>[97,168]</td>\n",
       "      <td>160000</td>\n",
       "      <td>4</td>\n",
       "      <td>4200</td>\n",
       "      <td>8</td>\n",
       "      <td>96</td>\n",
       "      <td>1000</td>\n",
       "      <td>3080</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  server_generation server_type release_time  purchase_price  slots_size  \\\n",
       "0            CPU.S1         CPU       [1,60]           15000           2   \n",
       "1            CPU.S2         CPU      [37,96]           16000           2   \n",
       "2            CPU.S3         CPU     [73,132]           19500           2   \n",
       "3            CPU.S4         CPU    [109,168]           22000           2   \n",
       "4            GPU.S1         GPU       [1,72]          120000           4   \n",
       "5            GPU.S2         GPU     [49,120]          140000           4   \n",
       "6            GPU.S3         GPU     [97,168]          160000           4   \n",
       "\n",
       "   energy_consumption  capacity  life_expectancy  cost_of_moving  \\\n",
       "0                 400        60               96            1000   \n",
       "1                 460        75               96            1000   \n",
       "2                 800       120               96            1000   \n",
       "3                 920       160               96            1000   \n",
       "4                3000         8               96            1000   \n",
       "5                3000         8               96            1000   \n",
       "6                4200         8               96            1000   \n",
       "\n",
       "   average_maintenance_fee  \n",
       "0                      288  \n",
       "1                      308  \n",
       "2                      375  \n",
       "3                      423  \n",
       "4                     2310  \n",
       "5                     2695  \n",
       "6                     3080  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df_servers = pd.read_csv('./data/servers.csv')\n",
    "df_servers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datacenter_id</th>\n",
       "      <th>cost_of_energy</th>\n",
       "      <th>latency_sensitivity</th>\n",
       "      <th>slots_capacity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DC1</td>\n",
       "      <td>0.25</td>\n",
       "      <td>low</td>\n",
       "      <td>25245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DC2</td>\n",
       "      <td>0.35</td>\n",
       "      <td>medium</td>\n",
       "      <td>15300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DC3</td>\n",
       "      <td>0.65</td>\n",
       "      <td>high</td>\n",
       "      <td>7020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DC4</td>\n",
       "      <td>0.75</td>\n",
       "      <td>high</td>\n",
       "      <td>8280</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  datacenter_id  cost_of_energy latency_sensitivity  slots_capacity\n",
       "0           DC1            0.25                 low           25245\n",
       "1           DC2            0.35              medium           15300\n",
       "2           DC3            0.65                high            7020\n",
       "3           DC4            0.75                high            8280"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_datacenters = pd.read_csv('./data/datacenters.csv')\n",
    "df_datacenters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import zipfile\n",
    "from typing import List\n",
    "import logging\n",
    "\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.INFO)\n",
    "logging.info(\"Logging started\")\n",
    "\n",
    "\n",
    "def zip_files(file_paths: List[str], output_zip: str):\n",
    "    \"\"\"\n",
    "    Zip multiple files into a single zip file.\n",
    "\n",
    "    :param file_paths: List of file paths to be zipped\n",
    "    :param output_zip: Name of the output zip file\n",
    "    \"\"\"\n",
    "    with zipfile.ZipFile(output_zip, 'w', compression=zipfile.ZIP_DEFLATED, compresslevel=9) as zipf:\n",
    "        for file in file_paths:\n",
    "            if os.path.exists(file):\n",
    "                zipf.write(file, os.path.basename(file))\n",
    "                logging.info(f\"Added {file} to {output_zip}\")\n",
    "            else:\n",
    "                logging.info(f\"Warning: {file} not found and skipped\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from seeds import known_seeds\n",
    "from utils import save_solution\n",
    "from scipy.stats import truncweibull_min\n",
    "from utils import (load_problem_data,\n",
    "                   load_solution)\n",
    "\n",
    "from evaluation import get_actual_demand, evaluation_function\n",
    "\n",
    "import uuid\n",
    "import tqdm\n",
    "import evaluation as evaluation_original\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def pad_array_to_multiple_of_12(arr):\n",
    "    # Get the current length of the array\n",
    "    current_length = len(arr)\n",
    "    \n",
    "    # Calculate how many elements we need to add\n",
    "    elements_to_add = (12 - (current_length % 12)) % 12\n",
    "    \n",
    "    # If elements_to_add is 0, it means the array is already divisible by 12\n",
    "    if elements_to_add == 0:\n",
    "        return arr\n",
    "    \n",
    "    # Create a new array with np.nan padding\n",
    "    padded_arr = np.pad(arr, (0, elements_to_add), mode='constant', constant_values=np.nan)\n",
    "    \n",
    "    return padded_arr\n",
    "\n",
    "# result = pad_array_to_multiple_of_12(demand_subarr_capped)\n",
    "# logging.info(f\"Original length: {len(demand_subarr_capped)}\")\n",
    "# print(f\"Padded length: {len(result)}\")\n",
    "# print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def fill_missing_timestep(df, min_time_step=1, max_time_step=168):\n",
    "    full_range = pd.DataFrame({'time_step': range(min_time_step, max_time_step + 1)})\n",
    "    df_filled = pd.merge(full_range, df, on='time_step', how='left')\n",
    "    numeric_columns = ['high', 'low', 'medium']\n",
    "    df_filled[numeric_columns] = df_filled[numeric_columns].fillna(0)\n",
    "    df_filled['server_generation'] = df_filled['server_generation'].ffill()\n",
    "    df_filled = df_filled.reset_index(drop=True)\n",
    "    return df_filled\n",
    "\n",
    "def parse_action_string(action_string):\n",
    "    server_generation, actions, action_params = action_string.split(\"|\")\n",
    "    actions = actions.split(\"-\")\n",
    "    action_params = action_params.split(\"-\")\n",
    "    action_comb = [parse_action_comb_param(server_generation, action, action_param) for action, action_param in zip(actions, action_params)]\n",
    "    action_comb = [action for action in action_comb if action is not None]\n",
    "    return action_comb\n",
    "    \n",
    "def parse_action_comb_param(server_generation, action, action_param):\n",
    "    if action == \"buy\":\n",
    "        datacenter_id, average_U = action_param.split(\",\")\n",
    "        average_U = float(average_U)\n",
    "        return {\"action\": action, \"datacenter_id\": datacenter_id, \"average_U\": average_U, \"server_generation\": server_generation}\n",
    "    elif action == \"dismiss\":\n",
    "        dismiss_age = int(action_param)\n",
    "        return {\"action\": action, \"dismiss_age\": dismiss_age, \"server_generation\": server_generation}\n",
    "    elif action == \"move\":\n",
    "        datacenter_id, average_U, move_age = action_param.split(\",\")\n",
    "        average_U = float(average_U)\n",
    "        move_age = int(move_age)\n",
    "        return {\"action\": action, \"datacenter_id\": datacenter_id, \"average_U\": average_U, \"move_age\": move_age,}\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "class Solution:\n",
    "\n",
    "    def __init__(self, df_servers, df_data_centers, df_selling_prices, time_steps=[1, 168], verbose=False):\n",
    "        self.df_servers = df_servers.copy()\n",
    "        self.df_servers['server_release_time_start'] = self.df_servers['release_time'].apply(lambda x: int(x.strip('[]').split(',')[0]))\n",
    "        self.df_servers['server_release_time_end'] = self.df_servers['release_time'].apply(lambda x: int(x.strip('[]').split(',')[1]))\n",
    "        \n",
    "        self.df_servers_dict = self.df_servers.set_index('server_generation').to_dict('index')\n",
    "\n",
    "        self.df_sell_prices = df_selling_prices.copy()\n",
    "        self.df_data_centers = df_data_centers.copy()\n",
    "        self.datacenter_ids_to_index = {datacenter_id: i for i, datacenter_id in enumerate(df_data_centers['datacenter_id'].values)}\n",
    "        self.df_datacenters_dict = self.df_data_centers.set_index('datacenter_id').to_dict('index')\n",
    "        self.time_steps = time_steps\n",
    "\n",
    "        self.verbose = verbose\n",
    "    \n",
    "        self.failure_rate = 0.07260491698699582\n",
    "\n",
    "        self.server_generation_unique = self.df_servers['server_generation'].unique()\n",
    "        self.server_generation_to_idx = {server_generation: i for i, server_generation in enumerate(self.server_generation_unique)}\n",
    "\n",
    "        self.sensitivity_unique = ['high', 'medium', 'low']\n",
    "        self.sensitivity_to_idx = {sensitivity: i for i, sensitivity in enumerate(self.sensitivity_unique)}\n",
    "\n",
    "        self.selling_prices = np.zeros((self.df_servers.shape[0], 1, len(self.sensitivity_unique)))\n",
    "        for i, row in self.df_sell_prices.iterrows():\n",
    "            server_idx = self.server_generation_to_idx[row['server_generation']]\n",
    "            sensitivity_idx = self.sensitivity_to_idx[row['latency_sensitivity']]\n",
    "            self.selling_prices[server_idx, 0, sensitivity_idx] = row['selling_price']\n",
    "\n",
    "        self.data_center_max_slots = np.zeros((self.df_data_centers.shape[0], self.time_steps[1]))\n",
    "        for i, row in self.df_data_centers.iterrows():\n",
    "            datacenter_idx = self.datacenter_ids_to_index[row['datacenter_id']]\n",
    "            self.data_center_max_slots[datacenter_idx] = row['slots_capacity']\n",
    "\n",
    "        self.historical_server_ids = [] # FOR ANALYSIS PERPOSES\n",
    "\n",
    "        self.id_count = 0\n",
    "\n",
    "    def generate_random_id(self,):\n",
    "        # self.id_count += 1\n",
    "        # return f\"ID-{self.id_count:09d}\"\n",
    "        return str(uuid.uuid4())\n",
    "    \n",
    "    def init_solution(self, ):\n",
    "        self.solution = []\n",
    "        \n",
    "        # initialize solution objectives\n",
    "        self.solution_Z = np.zeros((self.df_servers.shape[0], self.time_steps[1], len(self.sensitivity_unique)))\n",
    "        self.solution_L = np.zeros((self.time_steps[1],))\n",
    "        self.solution_R = np.zeros((self.time_steps[1],))\n",
    "        self.solution_C = np.zeros((self.time_steps[1],))\n",
    "        self.solution_num_servers = np.zeros((self.time_steps[1],))\n",
    "        self.data_center_slots = np.zeros((self.df_data_centers.shape[0], self.time_steps[1]))\n",
    "        self.solution_obj = 0\n",
    "\n",
    "    def load_solution(self, df_solution, demand):\n",
    "        self.load_demand(demand)\n",
    "        self.init_solution()\n",
    "\n",
    "        server_id_unique = df_solution['server_id'].unique()\n",
    "\n",
    "        for server_id in tqdm.tqdm(server_id_unique, desc=\"Loading solution\"):\n",
    "            df_solution_server_id = df_solution.loc[df_solution['server_id'] == server_id]\n",
    "            cur_num_servers, cur_Z, cur_L, cur_C, cur_data_center_slots = self.calculate_server_id(df_solution_server_id, append_to_solution=True)\n",
    "\n",
    "            new_num_servers, new_Z, new_L, new_C = self.calculate_new_obj_components(cur_num_servers=cur_num_servers,\n",
    "                                                                                    cur_Z=cur_Z,\n",
    "                                                                                    cur_L=cur_L,\n",
    "                                                                                    cur_C=cur_C)\n",
    "            new_obj, (new_num_servers, new_Z, new_L, new_C, new_U, new_R) = self.calculate_new_obj(new_num_servers=new_num_servers,\n",
    "                                                                                                    new_Z=new_Z,\n",
    "                                                                                                    new_L=new_L,\n",
    "                                                                                                    new_C=new_C)\n",
    "            self.update_new_obj(new_obj=new_obj,\n",
    "                                new_num_servers=new_num_servers,\n",
    "                                new_Z=new_Z,\n",
    "                                new_L=new_L,\n",
    "                                new_C=new_C,\n",
    "                                new_U=new_U,\n",
    "                                new_R=new_R,\n",
    "                                new_data_center_slots=self.data_center_slots + cur_data_center_slots)\n",
    "\n",
    "    def calculate_server_id(self, df_solution_server_id, append_to_solution=False):\n",
    "        # calculate objective functions for a single life cycle of a server\n",
    "        df_solution_server_id = df_solution_server_id.sort_values('time_step')\n",
    "        server_id = df_solution_server_id['server_id'].values[0]\n",
    "\n",
    "        server_generation = df_solution_server_id['server_generation'].values[0] \n",
    "        df_cur_server = self.df_servers_dict[server_generation]\n",
    "        server_idx = self.server_generation_to_idx[server_generation]\n",
    "        previous_time_step = 0\n",
    "        previous_datacenter_id = None\n",
    "        dismiss_age = None\n",
    "\n",
    "        cur_num_servers = np.zeros(self.solution_num_servers.shape)\n",
    "        cur_Z = np.zeros(self.solution_Z.shape)\n",
    "        cur_L = np.zeros((self.time_steps[1],))\n",
    "        cur_C = np.zeros((self.time_steps[1],))\n",
    "        cur_data_center_slots = np.zeros(self.data_center_slots.shape)\n",
    "        \n",
    "        for i, row in df_solution_server_id.iterrows():\n",
    "            action = row['action']\n",
    "            datacenter_id = row['datacenter_id']\n",
    "            cur_time_step = row['time_step']\n",
    "\n",
    "            if append_to_solution:\n",
    "                self.solution.append({\n",
    "                    \"time_step\": cur_time_step,\n",
    "                    \"action\": action,\n",
    "                    \"datacenter_id\": datacenter_id,\n",
    "                    \"server_generation\": server_generation,\n",
    "                    \"server_id\": server_id\n",
    "                })\n",
    "            \n",
    "            if action == \"buy\":\n",
    "                buy_time_step = cur_time_step\n",
    "                cur_C[buy_time_step - 1] += df_cur_server['purchase_price']\n",
    "\n",
    "            elif action != \"buy\":\n",
    "                previous_datacenter_idx = self.datacenter_ids_to_index[previous_datacenter_id]\n",
    "                previous_sensitivity = self.df_datacenters_dict[previous_datacenter_id]['latency_sensitivity']\n",
    "                previous_sensitivity_idx = self.sensitivity_to_idx[previous_sensitivity]\n",
    "                previous_datacenter_cost_of_energy = self.df_datacenters_dict[previous_datacenter_id]['cost_of_energy']\n",
    "\n",
    "                cur_data_center_slots[previous_datacenter_idx, previous_time_step - 1:cur_time_step - 1] += df_cur_server['slots_size']\n",
    "                cur_Z[server_idx, previous_time_step - 1:cur_time_step - 1, previous_sensitivity_idx] += df_cur_server['capacity']\n",
    "                cur_C[previous_time_step - 1:cur_time_step - 1] += previous_datacenter_cost_of_energy * df_cur_server['energy_consumption']\n",
    "                if action == \"move\":\n",
    "                    cur_C[cur_time_step - 1] += df_cur_server['cost_of_moving']\n",
    "                elif action == \"dismiss\":\n",
    "                    dismiss_age = cur_time_step - buy_time_step\n",
    "                \n",
    "            previous_time_step = cur_time_step\n",
    "            previous_datacenter_id = datacenter_id\n",
    "\n",
    "        if dismiss_age is None:\n",
    "            dismiss_age = min(df_cur_server['life_expectancy'], self.time_steps[1] - buy_time_step + 1)\n",
    "            cur_time_step = buy_time_step + dismiss_age\n",
    "\n",
    "            previous_datacenter_idx = self.datacenter_ids_to_index[previous_datacenter_id]\n",
    "            previous_sensitivity = self.df_datacenters_dict[previous_datacenter_id]['latency_sensitivity']\n",
    "            previous_sensitivity_idx = self.sensitivity_to_idx[previous_sensitivity]\n",
    "            previous_datacenter_cost_of_energy = self.df_datacenters_dict[previous_datacenter_id]['cost_of_energy']\n",
    "\n",
    "            cur_data_center_slots[previous_datacenter_idx, previous_time_step - 1:cur_time_step - 1] += df_cur_server['slots_size']\n",
    "            cur_Z[server_idx, previous_time_step - 1:cur_time_step - 1, previous_sensitivity_idx] += df_cur_server['capacity']\n",
    "            cur_C[previous_time_step - 1:cur_time_step - 1] += previous_datacenter_cost_of_energy * df_cur_server['energy_consumption']\n",
    "\n",
    "        start_idx = buy_time_step - 1\n",
    "        end_idx = buy_time_step + dismiss_age - 1\n",
    "        cur_L[start_idx:end_idx] = np.arange(1, dismiss_age + 1) / df_cur_server['life_expectancy']\n",
    "        cur_C[start_idx:end_idx] += df_cur_server['average_maintenance_fee'] \\\n",
    "            * (1+1.5 * np.arange(1, dismiss_age + 1) / df_cur_server['life_expectancy'] * np.log2(1.5 * np.arange(1, dismiss_age + 1) / df_cur_server['life_expectancy']))\n",
    "\n",
    "        cur_num_servers[start_idx:end_idx] = 1\n",
    "\n",
    "        return cur_num_servers, cur_Z, cur_L, cur_C, cur_data_center_slots\n",
    "                    \n",
    "\n",
    "    def load_demand(self, demand):\n",
    "        self.df_demand = demand.copy()\n",
    "        actual_demand_by_server_generation = {server_generation: demand[demand['server_generation'] == server_generation].sort_values('time_step') \n",
    "                                            for server_generation in self.server_generation_unique}\n",
    "        for key in actual_demand_by_server_generation:\n",
    "            actual_demand_by_server_generation[key] = fill_missing_timestep(actual_demand_by_server_generation[key])\n",
    "        self.actual_demand_by_server_generation = np.asarray([actual_demand_by_server_generation[server_generation][['high', 'medium', 'low']] \n",
    "                                                              for server_generation in self.server_generation_unique])\n",
    "        # self.actual_demand_by_server_generation shape is (num_server_generations, num_time_steps, num_sensitivity_levels)\n",
    "\n",
    "\n",
    "    def solve(self, demand, df_single_server):\n",
    "        self.df_single_server = df_single_server\n",
    "        self.load_demand(demand)\n",
    "        self.search_actions()\n",
    "        return self.solution\n",
    "    \n",
    "    def remove_nonprofit_server_ids(self, ):\n",
    "        n_removed = 0\n",
    "        total_gain = 0\n",
    "        df_solution = pd.DataFrame(self.solution)\n",
    "        df_solution_server_id = df_solution[df_solution['action'] == 'buy'].copy()\n",
    "\n",
    "        for server_id in tqdm.tqdm(df_solution_server_id['server_id'].values, desc=\"Removing non-profit servers\"):\n",
    "            df_solution_server_id_cur = df_solution.loc[df_solution['server_id'] == server_id]\n",
    "            cur_num_servers, cur_Z, cur_L, cur_C, cur_data_center_slots = self.calculate_server_id(df_solution_server_id_cur, append_to_solution=False)\n",
    "            \n",
    "            new_data_center_slots = self.data_center_slots  - cur_data_center_slots\n",
    "            new_num_servers = self.solution_num_servers - cur_num_servers\n",
    "            new_Z = self.solution_Z - cur_Z\n",
    "            new_L = (self.solution_L * self.solution_num_servers - cur_L * cur_num_servers) / np.maximum(new_num_servers, 1)\n",
    "            new_C = self.solution_C - cur_C\n",
    "\n",
    "            new_obj, (new_num_servers, new_Z, new_L, new_C, new_U, new_R) = self.calculate_new_obj(new_num_servers=new_num_servers,\n",
    "                                                                                                new_Z=new_Z,\n",
    "                                                                                                new_L=new_L,\n",
    "                                                                                                new_C=new_C)\n",
    "            \n",
    "            if new_obj <= self.solution_obj:\n",
    "                continue\n",
    "            \n",
    "            self.historical_server_ids.append({\n",
    "                \"solution_action\": \"remove\",\n",
    "                \"server_id\": server_id,\n",
    "                \"action_string\": None,\n",
    "                \"buy_time_step\": None,\n",
    "                \"new_solution_obj\": new_obj,\n",
    "                \"obj_gain\": new_obj - self.solution_obj,\n",
    "                \"merge_with\": None,\n",
    "            })\n",
    "            \n",
    "            total_gain += new_obj - self.solution_obj\n",
    "            n_removed += 1\n",
    "\n",
    "            self.update_new_obj(new_obj=new_obj,\n",
    "                                new_num_servers=new_num_servers,\n",
    "                                new_Z=new_Z,\n",
    "                                new_L=new_L,\n",
    "                                new_C=new_C,\n",
    "                                new_U=new_U,\n",
    "                                new_R=new_R,\n",
    "                                new_data_center_slots=new_data_center_slots)\n",
    "\n",
    "            # df_solution = df_solution.drop(df_solution[df_solution['server_id'] == server_id].index)\n",
    "            df_solution = df_solution[df_solution['server_id'] != server_id]\n",
    "            \n",
    "        self.solution = df_solution.sort_values([\"server_id\", \"time_step\",]).to_dict('records')\n",
    "        logging.info(f\"Removed {n_removed} servers with total gain {total_gain}\")\n",
    "\n",
    "    def merge_server_ids(self, merge_gap_sizes=range(10)):\n",
    "        df_solution = pd.DataFrame(self.solution)\n",
    "\n",
    "        total_gain = 0\n",
    "        n_merged = 0\n",
    "\n",
    "        # merging\n",
    "        for gap_size in tqdm.tqdm(merge_gap_sizes, desc=\"Merging servers\"):\n",
    "            for server_generation in self.server_generation_unique:\n",
    "                while True:\n",
    "                    df_solution_server = df_solution.loc[df_solution['server_generation'] == server_generation]\n",
    "                    df_solution_server_id = df_solution_server[df_solution_server['action'] == 'buy']\n",
    "                    df_solution_server_id = df_solution_server_id.set_index('server_id').join( \\\n",
    "                        df_solution_server[df_solution_server['action'] == 'move'][['server_id', 'time_step']].set_index('server_id'), \\\n",
    "                        rsuffix='_move')\n",
    "                    df_solution_server_id = df_solution_server_id.join( \\\n",
    "                        df_solution_server[df_solution_server['action'] == 'dismiss'][['server_id', 'time_step']].set_index('server_id'), \\\n",
    "                        rsuffix='_dismiss')\n",
    "\n",
    "                    # if time_step_dismiss is None then time_step_dismiss = time_step + 96\n",
    "                    df_solution_server_id['time_step_dismiss'] = df_solution_server_id['time_step_dismiss'].fillna(df_solution_server_id['time_step'] + 96)\n",
    "                    df_solution_server_id['age'] = df_solution_server_id['time_step_dismiss'] - df_solution_server_id['time_step']\n",
    "                    df_solution_server_id_with_dismiss = df_solution_server_id[df_solution_server_id['age'] < 96].reset_index(drop=False)\n",
    "\n",
    "                    # see if any server is dismissed before other servers are bought, every time_step_dismiss should be greater than time_step\n",
    "                    cross_diff = df_solution_server_id_with_dismiss['time_step'].values - df_solution_server_id_with_dismiss['time_step_dismiss'].values.reshape(-1, 1)\n",
    "\n",
    "                    indexes_1, indexes_2 = np.where(np.abs(cross_diff) <= gap_size)\n",
    "                    # indexes_1, indexes_2 = np.where(np.logical_and(cross_diff >= -gap_size, cross_diff <=  0))\n",
    "                    # indexes_1, indexes_2 = np.where(np.logical_and(cross_diff <= gap_size, cross_diff >=  0))\n",
    "                    removed_indexes_2 = set()\n",
    "                    changed = False\n",
    "                    for idx_1 in np.unique(indexes_1):\n",
    "                        idx_1 = idx_1.item()\n",
    "                        if idx_1 in removed_indexes_2:\n",
    "                            continue\n",
    "\n",
    "                        cur_age = df_solution_server_id_with_dismiss['age'].values[idx_1]\n",
    "                        cur_indexes_2 = indexes_2[indexes_1 == idx_1]\n",
    "\n",
    "                        # remove removed_indexes_2 from cur_indexes_2\n",
    "                        cur_indexes_2 = np.array([idx for idx in cur_indexes_2 if idx not in removed_indexes_2 and idx != idx_1])\n",
    "                        if len(cur_indexes_2) == 0:\n",
    "                            continue\n",
    "\n",
    "                        # check age\n",
    "                        cur_age_2 = df_solution_server_id_with_dismiss['age'].values[cur_indexes_2]\n",
    "                        cross_diff_2 = cross_diff[idx_1, cur_indexes_2]\n",
    "                        cur_indexes_2 = cur_indexes_2[cur_age + cur_age_2 + cross_diff_2 <= 96]\n",
    "                        if len(cur_indexes_2) == 0:\n",
    "                            continue\n",
    "\n",
    "                        cur_indexes_2_argsort = np.argsort(df_solution_server_id_with_dismiss['age'].values[cur_indexes_2])[::-1]\n",
    "                        cur_indexes_2 = cur_indexes_2[cur_indexes_2_argsort]\n",
    "                        for idx_2 in cur_indexes_2[:1]:\n",
    "\n",
    "                            server_id_1 = df_solution_server_id_with_dismiss['server_id'].values[idx_1]\n",
    "                            server_id_2 = df_solution_server_id_with_dismiss['server_id'].values[idx_2]\n",
    "\n",
    "                            df_solution_server_id_1 = df_solution_server.loc[df_solution_server['server_id'] \n",
    "                                                                                             == server_id_1].sort_values('time_step')\n",
    "                            df_solution_server_id_2 = df_solution_server.loc[df_solution_server['server_id'] \n",
    "                                                                                             == server_id_2].sort_values('time_step')\n",
    "\n",
    "                            \n",
    "                            # remove calculations for server_id_1 and server_id_2\n",
    "                            cur_num_servers_1, cur_Z_1, cur_L_1, cur_C_1, cur_data_center_slots_1 = self.calculate_server_id(df_solution_server_id_1, append_to_solution=False)\n",
    "                            cur_num_servers_2, cur_Z_2, cur_L_2, cur_C_2, cur_data_center_slots_2 = self.calculate_server_id(df_solution_server_id_2, append_to_solution=False)\n",
    "\n",
    "                            df_solution_new_server_id = pd.concat([df_solution_server_id_1, df_solution_server_id_2]).sort_values('time_step')\n",
    "\n",
    "                            # drop dismiss of the server_id_1\n",
    "                            df_solution_new_server_id = df_solution_new_server_id[np.logical_not(np.logical_and(df_solution_new_server_id['action'] == 'dismiss',\n",
    "                                                                                                                df_solution_new_server_id['server_id'] == server_id_1))]\n",
    "                            \n",
    "                            # change buy of server_id_2 to move\n",
    "                            df_solution_new_server_id.loc[np.logical_and(df_solution_new_server_id['action'] == 'buy',\n",
    "                                                                        df_solution_new_server_id['server_id'] == server_id_2), 'action'] = 'move'\n",
    "                            \n",
    "                            df_solution_new_server_id['server_id'] = server_id_1\n",
    "\n",
    "                            cur_num_servers_new, cur_Z_new, cur_L_new, cur_C_new, cur_data_center_slots_new = self.calculate_server_id(df_solution_new_server_id, append_to_solution=False)\n",
    "\n",
    "                            new_data_center_slots = self.data_center_slots + cur_data_center_slots_new - cur_data_center_slots_1 - cur_data_center_slots_2 \n",
    "                            if np.any(self.data_center_max_slots < new_data_center_slots):\n",
    "                                continue\n",
    "\n",
    "                            new_num_servers = self.solution_num_servers + cur_num_servers_new - cur_num_servers_1 - cur_num_servers_2\n",
    "                            new_Z = self.solution_Z + cur_Z_new - cur_Z_1 - cur_Z_2\n",
    "                            new_L = (self.solution_L * self.solution_num_servers + cur_L_new * cur_num_servers_new - cur_L_1 * cur_num_servers_1 - cur_L_2 * cur_num_servers_2) / np.maximum(new_num_servers, 1)\n",
    "                            new_C = self.solution_C + cur_C_new - cur_C_1 - cur_C_2\n",
    "\n",
    "                            new_obj, (new_num_servers, new_Z, new_L, new_C, new_U, new_R) = self.calculate_new_obj(new_num_servers=new_num_servers,\n",
    "                                                                                                                new_Z=new_Z,\n",
    "                                                                                                                new_L=new_L,\n",
    "                                                                                                                new_C=new_C)\n",
    "\n",
    "                            if new_obj <= self.solution_obj:\n",
    "                                continue\n",
    "\n",
    "                            total_gain += new_obj - self.solution_obj\n",
    "                            n_merged += 1\n",
    "                            \n",
    "                            self.update_new_obj(new_obj=new_obj,\n",
    "                                                new_num_servers=new_num_servers,\n",
    "                                                new_Z=new_Z,\n",
    "                                                new_L=new_L,\n",
    "                                                new_C=new_C,\n",
    "                                                new_U=new_U,\n",
    "                                                new_R=new_R,\n",
    "                                                new_data_center_slots=new_data_center_slots)\n",
    "                            \n",
    "                            df_solution = df_solution[np.logical_not(np.logical_or(df_solution['server_id'] == server_id_1, \n",
    "                                                                                   df_solution['server_id'] == server_id_2))]\n",
    "                            df_solution = pd.concat([df_solution, df_solution_new_server_id])\n",
    "\n",
    "                            self.historical_server_ids.append({\n",
    "                                \"solution_action\": \"merge\",\n",
    "                                \"server_id\": server_id_1,\n",
    "                                \"action_string\": None,\n",
    "                                \"buy_time_step\": None,\n",
    "                                \"new_solution_obj\": new_obj,\n",
    "                                \"obj_gain\": new_obj - self.solution_obj,\n",
    "                                \"merge_with\": server_id_2,\n",
    "                            })\n",
    "                            \n",
    "                            removed_indexes_2.add(idx_1)\n",
    "                            removed_indexes_2.add(idx_2)\n",
    "                            changed = True\n",
    "                            break\n",
    "                    if not changed:\n",
    "                        break\n",
    "        logging.info(f\"Merged {n_merged} servers with total gain {total_gain}\")\n",
    "        \n",
    "        self.solution = df_solution.sort_values([\"server_id\", \"time_step\",]).to_dict('records')\n",
    "\n",
    "    \n",
    "    def search_actions(self,):\n",
    "\n",
    "        currennt_n_buys = len([action for action in self.solution if action['action'] == 'buy'])\n",
    "        cur_obj = self.solution_obj\n",
    "\n",
    "        for action_string in tqdm.tqdm(self.df_single_server['action_string'].values, desc=\"Searching actions\"):\n",
    "            if \"|buy-dismiss|\" in action_string:\n",
    "                self.search_buy_dismiss_combination(action_string)\n",
    "            elif \"|buy-move-dismiss|\" in action_string:\n",
    "                self.search_buy_move_dismiss_combination(action_string)\n",
    "\n",
    "        new_n_buys = len([action for action in self.solution if action['action'] == 'buy'])\n",
    "        new_obj = self.solution_obj\n",
    "\n",
    "        logging.info(f\"Added {new_n_buys - currennt_n_buys} servers with total gain {new_obj - cur_obj}\")\n",
    "\n",
    "    def search_buy_move_dismiss_combination(self, action_string):\n",
    "        action_comb = parse_action_string(action_string)\n",
    "\n",
    "        server_generation = action_comb[0]['server_generation']\n",
    "\n",
    "        datacenter_id_1 = action_comb[0]['datacenter_id']\n",
    "        datacenter_id_2 = action_comb[1]['datacenter_id']\n",
    "\n",
    "        move_age = action_comb[1]['move_age']\n",
    "        dissmiss_age = action_comb[2]['dismiss_age']\n",
    "\n",
    "\n",
    "        df_cur_server = self.df_servers_dict[server_generation]\n",
    "        df_datacenter_1 = self.df_datacenters_dict[datacenter_id_1]\n",
    "        df_datacenter_2 = self.df_datacenters_dict[datacenter_id_2]\n",
    "\n",
    "        utilization_threshold_1 = action_comb[0]['average_U']\n",
    "        utilization_threshold_2 = action_comb[1]['average_U']\n",
    "\n",
    "        sensitivity_1 = df_datacenter_1['latency_sensitivity']\n",
    "        sensitivity_2 = df_datacenter_2['latency_sensitivity']\n",
    "\n",
    "        datacenter_cost_of_energy_1 = df_datacenter_1['cost_of_energy']\n",
    "        datacenter_cost_of_energy_2 = df_datacenter_2['cost_of_energy']\n",
    "\n",
    "        server_capacity = df_cur_server['capacity']\n",
    "        server_energy_consumption = df_cur_server['energy_consumption']\n",
    "        server_life_expectancy = df_cur_server['life_expectancy']\n",
    "        server_average_maintenance_fee = df_cur_server['average_maintenance_fee']\n",
    "        server_purchase_price = df_cur_server['purchase_price']\n",
    "        server_cost_of_moving = df_cur_server['cost_of_moving']\n",
    "        server_slots_size = df_cur_server['slots_size']\n",
    "        server_release_time_start = df_cur_server['server_release_time_start']\n",
    "        server_release_time_end = df_cur_server['server_release_time_end']\n",
    "\n",
    "        datacenter_idx_1 = self.datacenter_ids_to_index[datacenter_id_1]\n",
    "        datacenter_idx_2 = self.datacenter_ids_to_index[datacenter_id_2]\n",
    "        server_idx = self.server_generation_to_idx[server_generation]\n",
    "        sensitivity_idx_1 = self.sensitivity_to_idx[sensitivity_1]\n",
    "        sensitivity_idx_2 = self.sensitivity_to_idx[sensitivity_2]\n",
    "\n",
    "        demand_arr_1 = self.actual_demand_by_server_generation[server_idx, :, self.sensitivity_to_idx[sensitivity_1]]\n",
    "        demand_arr_2 = self.actual_demand_by_server_generation[server_idx, :, self.sensitivity_to_idx[sensitivity_2]]\n",
    "        total_buys = 0\n",
    "        for buy_time_step in range(server_release_time_start, server_release_time_end + 1):\n",
    "            start_idx_1 = buy_time_step - 1\n",
    "            end_idx_1 = buy_time_step + move_age - 1\n",
    "            start_idx_2 = buy_time_step + move_age - 1\n",
    "            end_idx_2 = buy_time_step + dissmiss_age - 1\n",
    "\n",
    "            demand_subarr_1 = demand_arr_1[start_idx_1:end_idx_1]\n",
    "            demand_subarr_2 = demand_arr_2[start_idx_2:end_idx_2]\n",
    "            if demand_subarr_1.shape[0] < move_age or demand_subarr_1.shape[0] + demand_subarr_2.shape[0] < dissmiss_age:\n",
    "                break\n",
    "\n",
    "            while True:\n",
    "\n",
    "                # check utilization condition for datacenter 1\n",
    "                demand_subarr_1_capped = np.minimum(demand_subarr_1, server_capacity)\n",
    "                # if demand_subarr_1_capped[0] / server_capacity < utilization_threshold_1: # check the first time step\n",
    "                #     break\n",
    "\n",
    "                demand_subarr_1_capped = pad_array_to_multiple_of_12(demand_subarr_1_capped)\n",
    "                demand_subarr_1_capped = demand_subarr_1_capped.reshape(-1, 12)\n",
    "                average_utilization_1 = np.nanmean(demand_subarr_1_capped / server_capacity, axis=1)\n",
    "                if np.any(average_utilization_1 < utilization_threshold_1):\n",
    "                    break\n",
    "\n",
    "                # check utilization condition for datacenter 2\n",
    "                demand_subarr_2_capped = np.minimum(demand_subarr_2, server_capacity)\n",
    "                demand_subarr_2_capped = pad_array_to_multiple_of_12(demand_subarr_2_capped)\n",
    "                demand_subarr_2_capped = demand_subarr_2_capped.reshape(-1, 12)\n",
    "                average_utilization_2 = np.nanmean(demand_subarr_2_capped / server_capacity, axis=1)\n",
    "                if np.any(average_utilization_2 < utilization_threshold_2):\n",
    "                    break\n",
    "\n",
    "                # check data center slots\n",
    "                new_data_center_slots = np.copy(self.data_center_slots)\n",
    "                new_data_center_slots[datacenter_idx_1, start_idx_1:end_idx_1] += server_slots_size\n",
    "                new_data_center_slots[datacenter_idx_2, start_idx_2:end_idx_2] += server_slots_size\n",
    "                if np.any(self.data_center_max_slots < new_data_center_slots):\n",
    "                    break\n",
    "\n",
    "                # check if adding the server is beneficial by calculating the objective function\n",
    "\n",
    "                ### calculate for the new server\n",
    "                cur_Z = np.zeros(self.solution_Z.shape)\n",
    "                cur_Z[server_idx, start_idx_1:end_idx_1, sensitivity_idx_1] = server_capacity\n",
    "                cur_Z[server_idx, start_idx_2:end_idx_2, sensitivity_idx_2] = server_capacity\n",
    "\n",
    "                cur_L = np.zeros(self.solution_L.shape)\n",
    "                cur_L[start_idx_1:end_idx_2] = np.arange(1, dissmiss_age + 1) / server_life_expectancy\n",
    "\n",
    "                cur_E = np.zeros(self.solution_L.shape)\n",
    "                cur_E[start_idx_1:end_idx_2] = datacenter_cost_of_energy_1 * server_energy_consumption\n",
    "                cur_E[start_idx_2:end_idx_2] = datacenter_cost_of_energy_2 * server_energy_consumption\n",
    "\n",
    "                cur_alpha = np.zeros(self.solution_L.shape)\n",
    "                cur_alpha[start_idx_1:end_idx_2] = server_average_maintenance_fee \\\n",
    "                    * (1+1.5 * np.arange(1, dissmiss_age + 1) / server_life_expectancy * np.log2(1.5 * np.arange(1, dissmiss_age + 1) / server_life_expectancy))\n",
    "                cur_C = cur_E + cur_alpha\n",
    "                cur_C[start_idx_1] += server_purchase_price\n",
    "                cur_C[start_idx_2] += server_cost_of_moving\n",
    "\n",
    "                cur_num_servers = np.zeros(self.solution_L.shape)\n",
    "                cur_num_servers[start_idx_1:end_idx_2] = 1\n",
    "\n",
    "                new_num_servers, new_Z, new_L, new_C = self.calculate_new_obj_components(cur_num_servers=cur_num_servers,\n",
    "                                                                                        cur_Z=cur_Z,\n",
    "                                                                                        cur_L=cur_L,\n",
    "                                                                                        cur_C=cur_C)\n",
    "                new_obj, (new_num_servers, new_Z, new_L, new_C, new_U, new_R) = self.calculate_new_obj(new_num_servers=new_num_servers,\n",
    "                                                                                                    new_Z=new_Z,\n",
    "                                                                                                    new_L=new_L,\n",
    "                                                                                                    new_C=new_C)\n",
    "                if new_obj - self.solution_obj <= 0:\n",
    "                    break\n",
    "                new_server_id = self.generate_random_id()\n",
    "                \n",
    "                self.historical_server_ids.append({\n",
    "                    \"solution_action\": \"add\",\n",
    "                    \"server_id\": new_server_id,\n",
    "                    \"action_string\": action_string,\n",
    "                    \"buy_time_step\": buy_time_step,\n",
    "                    \"new_solution_obj\": new_obj,\n",
    "                    \"obj_gain\": new_obj - self.solution_obj,\n",
    "                    \"merge_with\": None,\n",
    "                })\n",
    "\n",
    "                self.update_new_obj(new_obj=new_obj,\n",
    "                                    new_num_servers=new_num_servers,\n",
    "                                    new_Z=new_Z,\n",
    "                                    new_L=new_L,\n",
    "                                    new_C=new_C,\n",
    "                                    new_U=new_U,\n",
    "                                    new_R=new_R,\n",
    "                                    new_data_center_slots=new_data_center_slots)\n",
    "\n",
    "                self.add_buy_move_dismiss_action(datacenter_id_1=datacenter_id_1,\n",
    "                                                    datacenter_id_2=datacenter_id_2,\n",
    "                                                    server_generation=server_generation,\n",
    "                                                    move_age=move_age,\n",
    "                                                    dismiss_age=dissmiss_age,\n",
    "                                                    time_step=buy_time_step,\n",
    "                                                    server_id=new_server_id)\n",
    "                total_buys += 1\n",
    "        # if self.verbose and total_buys > 0:\n",
    "        #     print(f\"Bought {total_buys} servers with action string {action_string}\")\n",
    "\n",
    "        \n",
    "    def search_buy_dismiss_combination(self, action_string, ):\n",
    "        action_comb = parse_action_string(action_string)\n",
    "\n",
    "        server_generation = action_comb[0]['server_generation']\n",
    "        datacenter_id = action_comb[0]['datacenter_id']\n",
    "\n",
    "        df_cur_server = self.df_servers_dict[server_generation]\n",
    "        df_datacenter = self.df_datacenters_dict[datacenter_id]\n",
    "\n",
    "        utilization_threshold = action_comb[0]['average_U']\n",
    "\n",
    "        sensitivity = df_datacenter['latency_sensitivity']\n",
    "        datacenter_cost_of_energy = df_datacenter['cost_of_energy']\n",
    "\n",
    "        server_capacity = df_cur_server['capacity']\n",
    "        server_energy_consumption = df_cur_server['energy_consumption']\n",
    "        server_life_expectancy = df_cur_server['life_expectancy']\n",
    "        server_average_maintenance_fee = df_cur_server['average_maintenance_fee']\n",
    "        server_purchase_price = df_cur_server['purchase_price']\n",
    "        server_slots_size = df_cur_server['slots_size']\n",
    "        server_release_time_start = df_cur_server['server_release_time_start']\n",
    "        server_release_time_end = df_cur_server['server_release_time_end']\n",
    "        dissmiss_age = action_comb[1]['dismiss_age']\n",
    "\n",
    "        datacenter_idx = self.datacenter_ids_to_index[datacenter_id]\n",
    "        server_idx = self.server_generation_to_idx[server_generation]\n",
    "        sensitivity_idx = self.sensitivity_to_idx[sensitivity]\n",
    "        demand_arr = self.actual_demand_by_server_generation[server_idx, :, sensitivity_idx]\n",
    "        total_buys = 0\n",
    "        for buy_time_step in range(server_release_time_start, server_release_time_end + 1):\n",
    "            start_idx = buy_time_step - 1\n",
    "            end_idx = buy_time_step + dissmiss_age - 1\n",
    "            demand_subarr = demand_arr[start_idx:end_idx]\n",
    "            if demand_subarr.shape[0] < dissmiss_age:\n",
    "                break\n",
    "\n",
    "            while True:\n",
    "                # check utilization condition\n",
    "                demand_subarr_capped = np.minimum(demand_subarr, server_capacity)\n",
    "\n",
    "                # if demand_subarr_capped[0] / server_capacity < utilization_threshold: # check the first time step\n",
    "                #     break\n",
    "                \n",
    "                demand_subarr_capped = pad_array_to_multiple_of_12(demand_subarr_capped)\n",
    "                demand_subarr_capped = demand_subarr_capped.reshape(-1, 12)\n",
    "                average_utilization = np.nanmean(demand_subarr_capped / server_capacity, axis=1)\n",
    "                if np.any(average_utilization < utilization_threshold):\n",
    "                    break\n",
    "\n",
    "                # check data center slots\n",
    "                new_data_center_slots = np.copy(self.data_center_slots)\n",
    "                new_data_center_slots[datacenter_idx, start_idx:end_idx] += server_slots_size\n",
    "\n",
    "                if np.any(self.data_center_max_slots < new_data_center_slots):\n",
    "                    break\n",
    "                \n",
    "                # check if adding the server is beneficial by calculating the objective function\n",
    "                cur_Z = np.zeros(self.solution_Z.shape)\n",
    "                cur_Z[server_idx, start_idx:end_idx, sensitivity_idx] = server_capacity\n",
    "                \n",
    "                cur_L = np.zeros((self.time_steps[1],))\n",
    "                cur_L[start_idx:end_idx] = np.arange(1, dissmiss_age + 1) / server_life_expectancy\n",
    "\n",
    "                cur_E = np.zeros((self.time_steps[1],))\n",
    "                cur_E[start_idx:end_idx] = datacenter_cost_of_energy * server_energy_consumption\n",
    "\n",
    "                cur_alpha = np.zeros((self.time_steps[1],))\n",
    "                cur_alpha[start_idx:end_idx] = server_average_maintenance_fee \\\n",
    "                    * (1+1.5 * np.arange(1, dissmiss_age + 1) / server_life_expectancy * np.log2(1.5 * np.arange(1, dissmiss_age + 1) / server_life_expectancy))\n",
    "                cur_C = cur_E + cur_alpha\n",
    "                cur_C[start_idx] += server_purchase_price\n",
    "\n",
    "                cur_num_servers = np.zeros((self.time_steps[1],))\n",
    "                cur_num_servers[start_idx:end_idx] = 1\n",
    "\n",
    "\n",
    "                new_num_servers, new_Z, new_L, new_C = self.calculate_new_obj_components(cur_num_servers=cur_num_servers,\n",
    "                                                                                        cur_Z=cur_Z,\n",
    "                                                                                        cur_L=cur_L,\n",
    "                                                                                        cur_C=cur_C)\n",
    "                new_obj, (new_num_servers, new_Z, new_L, new_C, new_U, new_R) = self.calculate_new_obj(new_num_servers=new_num_servers,\n",
    "                                                                                                       new_Z=new_Z,\n",
    "                                                                                                       new_L=new_L,\n",
    "                                                                                                       new_C=new_C)\n",
    "                if new_obj - self.solution_obj <= 0:\n",
    "                    break\n",
    "\n",
    "                new_server_id = self.generate_random_id()\n",
    "                \n",
    "                self.historical_server_ids.append({\n",
    "                    \"solution_action\": \"add\",\n",
    "                    \"server_id\": new_server_id,\n",
    "                    \"action_string\": action_string,\n",
    "                    \"buy_time_step\": buy_time_step,\n",
    "                    \"new_solution_obj\": new_obj,\n",
    "                    \"obj_gain\": new_obj - self.solution_obj,\n",
    "                    \"merge_with\": None,\n",
    "                })\n",
    "                self.update_new_obj(new_obj=new_obj,\n",
    "                                    new_num_servers=new_num_servers,\n",
    "                                    new_Z=new_Z,\n",
    "                                    new_L=new_L,\n",
    "                                    new_C=new_C,\n",
    "                                    new_U=new_U,\n",
    "                                    new_R=new_R,\n",
    "                                    new_data_center_slots=new_data_center_slots)\n",
    "                \n",
    "                self.add_buy_dismiss_action(datacenter_id=datacenter_id, \n",
    "                                        server_generation=server_generation, \n",
    "                                        dismiss_age=dissmiss_age, \n",
    "                                        time_step=buy_time_step,\n",
    "                                        server_id=new_server_id)\n",
    "                total_buys += 1\n",
    "                    \n",
    "        # if self.verbose and total_buys > 0:\n",
    "        #     logging.info(f\"Bought {total_buys} servers with action string {action_string}\")\n",
    "\n",
    "    def calculate_new_obj_components(self, cur_num_servers, cur_Z, cur_L, cur_C):\n",
    "        new_num_servers = self.solution_num_servers + cur_num_servers\n",
    "        new_Z = self.solution_Z + cur_Z\n",
    "        new_L = (self.solution_L * self.solution_num_servers + cur_L * cur_num_servers) / np.maximum(new_num_servers, 1)\n",
    "        new_C = self.solution_C + cur_C\n",
    "        return new_num_servers, new_Z, new_L, new_C\n",
    "\n",
    "    def calculate_new_obj(self, new_num_servers, new_Z, new_L, new_C):\n",
    "\n",
    "        new_Z_failure = (new_Z * (1-self.failure_rate)).astype(int)\n",
    "        new_Z_failure_demand = np.minimum(new_Z_failure, self.actual_demand_by_server_generation)\n",
    "        new_U = np.where(new_Z_failure > 0.5,\n",
    "                            new_Z_failure_demand / np.maximum(1.0, new_Z_failure),\n",
    "                            np.nan)\n",
    "        new_U = np.nanmean(new_U, axis=(0, 2))\n",
    "        new_U = np.nan_to_num(new_U, nan=0)\n",
    "\n",
    "        new_R = new_Z_failure_demand * self.selling_prices\n",
    "        new_R = np.nansum(new_R, axis=(0, 2))\n",
    "\n",
    "        new_obj = new_U * new_L * (new_R - new_C)\n",
    "        new_obj = np.nansum(new_obj)\n",
    "\n",
    "        return new_obj, (new_num_servers, new_Z, new_L, new_C, new_U, new_R)\n",
    "    \n",
    "    def update_new_obj(self, new_obj, new_num_servers, new_Z, new_L, new_C, new_U, new_R, new_data_center_slots):\n",
    "        self.solution_obj = new_obj\n",
    "        self.solution_Z = new_Z\n",
    "        self.solution_L = new_L\n",
    "        self.solution_C = new_C\n",
    "        self.solution_R = new_R\n",
    "        self.solution_U = new_U\n",
    "        self.solution_num_servers = new_num_servers\n",
    "        self.data_center_slots = new_data_center_slots\n",
    "\n",
    "\n",
    "\n",
    "    def add_buy_move_dismiss_action(self, datacenter_id_1, datacenter_id_2, server_generation, move_age, dismiss_age, time_step, server_id=None):\n",
    "        server_life_expectancy = self.df_servers_dict[server_generation]['life_expectancy']\n",
    "        if server_id is None:\n",
    "            server_id = self.generate_random_id()\n",
    "        self.solution.append({\n",
    "            \"time_step\": time_step,\n",
    "            \"action\": \"buy\",\n",
    "            \"datacenter_id\": datacenter_id_1,\n",
    "            \"server_generation\": server_generation,\n",
    "            \"server_id\": server_id\n",
    "        })\n",
    "\n",
    "        if time_step + move_age <= self.time_steps[1]:\n",
    "            self.solution.append({\n",
    "                \"time_step\": time_step + move_age,\n",
    "                \"action\": \"move\",\n",
    "                \"datacenter_id\": datacenter_id_2,\n",
    "                \"server_generation\": server_generation,\n",
    "                \"server_id\": server_id\n",
    "            })\n",
    "\n",
    "        if dismiss_age < server_life_expectancy and time_step + dismiss_age <= self.time_steps[1]:\n",
    "            self.solution.append({\n",
    "                \"time_step\": time_step + dismiss_age,\n",
    "                \"action\": \"dismiss\",\n",
    "                \"datacenter_id\": datacenter_id_2,\n",
    "                \"server_generation\": server_generation,\n",
    "                \"server_id\": server_id\n",
    "            })\n",
    "\n",
    "    def add_buy_dismiss_action(self, datacenter_id, server_generation, dismiss_age, time_step, server_id=None):\n",
    "        server_life_expectancy = self.df_servers_dict[server_generation]['life_expectancy']\n",
    "        \n",
    "        if server_id is None:\n",
    "            server_id = self.generate_random_id()\n",
    "        self.solution.append({\n",
    "            \"time_step\": time_step,\n",
    "            \"action\": \"buy\",\n",
    "            \"datacenter_id\": datacenter_id,\n",
    "            \"server_generation\": server_generation,\n",
    "            \"server_id\": server_id\n",
    "        })\n",
    "        if dismiss_age < server_life_expectancy and time_step + dismiss_age <= self.time_steps[1]:\n",
    "            self.solution.append({\n",
    "                \"time_step\": time_step + dismiss_age,\n",
    "                \"action\": \"dismiss\",\n",
    "                \"datacenter_id\": datacenter_id,\n",
    "                \"server_generation\": server_generation,\n",
    "                \"server_id\": server_id\n",
    "            })\n",
    "\n",
    "    def save_checkpoint(self, path):\n",
    "        data = {\n",
    "            \"solution\": self.solution,\n",
    "            \"solution_num_servers\": self.solution_num_servers,\n",
    "            \"solution_Z\": self.solution_Z,\n",
    "            \"solution_L\": self.solution_L,\n",
    "            \"solution_C\": self.solution_C,\n",
    "            \"datacenter_slots\": self.data_center_slots,\n",
    "            \"historical_server_ids\": self.historical_server_ids\n",
    "        }\n",
    "\n",
    "        with open(path, 'wb') as f:\n",
    "            pickle.dump(data, f)\n",
    "\n",
    "    def load_checkpoint(self, path, demand):\n",
    "        with open(path, 'rb') as f:\n",
    "            data = pickle.load(f)\n",
    "            self.solution = data['solution']\n",
    "            cur_num_servers = data['solution_num_servers']\n",
    "            cur_Z = data['solution_Z']\n",
    "            cur_L = data['solution_L']\n",
    "            cur_C = data['solution_C']\n",
    "            cur_data_center_slots = data['datacenter_slots']\n",
    "            self.historical_server_ids = data['historical_server_ids']\n",
    "\n",
    "            self.load_demand(demand)\n",
    "\n",
    "            new_obj, (new_num_servers, new_Z, new_L, new_C, new_U, new_R) = self.calculate_new_obj(new_num_servers=cur_num_servers,\n",
    "                                                                                                new_Z=cur_Z,\n",
    "                                                                                                new_L=cur_L,\n",
    "                                                                                                new_C=cur_C)\n",
    "            self.update_new_obj(new_obj=new_obj,\n",
    "                                new_num_servers=new_num_servers,\n",
    "                                new_Z=new_Z,\n",
    "                                new_L=new_L,\n",
    "                                new_C=new_C,\n",
    "                                new_U=new_U,\n",
    "                                new_R=new_R,\n",
    "                                new_data_center_slots=cur_data_center_slots)\n",
    "            \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "\n",
    "def get_my_solution(d, df_single_server=None, verbose=False, failure_rate_r=0.0, df_solution=None, output_file=None, restore_checkpoint_path=None, checkpoint_path=None, n_solving_loops=5):\n",
    "    _, df_datacenters, df_servers, df_selling_prices = load_problem_data()\n",
    "    if df_single_server is None:\n",
    "        df_single_server = pd.read_csv(\"df_single_server_results_v2.csv\")\n",
    "        df_single_server = df_single_server[df_single_server['score'] > 0]\n",
    "        df_single_server = df_single_server.loc[:int(len(df_single_server) * 0.58)]\n",
    "    solution = Solution(df_servers=df_servers, \n",
    "                        df_data_centers=df_datacenters, \n",
    "                        df_selling_prices=df_selling_prices,\n",
    "                        verbose=verbose)\n",
    "    solution.failure_rate = 0.07260491698699582 * failure_rate_r\n",
    "    if restore_checkpoint_path is not None and os.path.exists(restore_checkpoint_path):\n",
    "        solution.load_checkpoint(restore_checkpoint_path, demand=d)\n",
    "    elif df_solution is not None:\n",
    "        solution.load_solution(df_solution, demand=d)\n",
    "    else:\n",
    "        solution.init_solution()\n",
    "    best_obj = solution.solution_obj\n",
    "    logging.info(f\"Initial solution: {solution.solution_obj}\")\n",
    "\n",
    "    \n",
    "    def save_checkpoint():\n",
    "        if output_file is not None:\n",
    "            save_solution(solution.solution, output_file)\n",
    "        if checkpoint_path is not None:\n",
    "            solution.save_checkpoint(checkpoint_path)\n",
    "\n",
    "    for _ in range(n_solving_loops):\n",
    "        solution.solve(d, df_single_server=df_single_server)\n",
    "        if solution.solution_obj > best_obj:\n",
    "            logging.info(f\"New best solution: {solution.solution_obj}\")\n",
    "            best_obj = solution.solution_obj\n",
    "            save_checkpoint()\n",
    "\n",
    "        solution.merge_server_ids(merge_gap_sizes=range(12))\n",
    "        if solution.solution_obj > best_obj:\n",
    "            logging.info(f\"New best solution: {solution.solution_obj}\")\n",
    "            best_obj = solution.solution_obj\n",
    "            save_checkpoint()\n",
    "\n",
    "        solution.remove_nonprofit_server_ids()\n",
    "        if solution.solution_obj > best_obj:\n",
    "            logging.info(f\"New best solution: {solution.solution_obj}\")\n",
    "            best_obj = solution.solution_obj\n",
    "            save_checkpoint()\n",
    "    return solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# solving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "def solve_seed(seed):\n",
    "    OUTPUT_FOLDER = \"output_13v2\"\n",
    "    if not os.path.exists(OUTPUT_FOLDER):\n",
    "        os.makedirs(OUTPUT_FOLDER)\n",
    "    demand, datacenters, servers, selling_prices = load_problem_data()\n",
    "\n",
    "\n",
    "    df_single_server_v2 = pd.read_csv(\"df_single_server_results_v6_buydismiss_UP.csv\")\n",
    "    df_single_server_v3 = pd.read_csv(\"df_single_server_results_v6_buymovedismiss_UP.csv\")\n",
    "    list_df_v3_filtered = []\n",
    "    for server_generataion in df_single_server_v3['server_generation'].unique():\n",
    "        df_server_generation = df_single_server_v3[df_single_server_v3['server_generation'] == server_generataion]\n",
    "        df_server_generation = df_server_generation.iloc[:int(len(df_server_generation) * 0.2)]\n",
    "        list_df_v3_filtered.append(df_server_generation)\n",
    "    df_single_server_v3_filtered = pd.concat(list_df_v3_filtered)\n",
    "    df_single_server_v3_filtered = df_single_server_v3_filtered.sort_values('score_per_slot', ascending=False).reset_index(drop=True)\n",
    "    df_single_server = pd.concat([df_single_server_v2, df_single_server_v3_filtered])\n",
    "    df_single_server['action_comb'] = df_single_server['action_string'].apply(parse_action_string)\n",
    "\n",
    "    total_score = 0\n",
    "\n",
    "    list_solution = []\n",
    "    list_real_scores = []\n",
    "\n",
    "    np.random.seed(seed)\n",
    "    actual_demand = get_actual_demand(demand)\n",
    "\n",
    "    solution = get_my_solution(actual_demand, \n",
    "                            df_single_server=df_single_server,\n",
    "                            verbose=False,\n",
    "                            failure_rate_r=1.0,\n",
    "                            output_file=f\"./{OUTPUT_FOLDER}/{seed}.json\",\n",
    "                            restore_checkpoint_path=f\"./{OUTPUT_FOLDER}/{seed}.pkl\",\n",
    "                            checkpoint_path=f\"./{OUTPUT_FOLDER}/{seed}.pkl\",\n",
    "                            n_solving_loops=10) \n",
    "    \n",
    "    \n",
    "    df_solution = pd.DataFrame(solution.solution)\n",
    "\n",
    "    score = evaluation_original.evaluation_function(df_solution,\n",
    "                                demand,\n",
    "                                datacenters,\n",
    "                                servers,\n",
    "                                selling_prices,\n",
    "                                seed=seed,\n",
    "                                verbose=False)\n",
    "    logging.info(f\"Seed: {seed}, Score: {score}, solution obj {solution.solution_obj}\")\n",
    "    total_score += score\n",
    "\n",
    "    list_solution.append(solution)\n",
    "    list_real_scores.append(score)\n",
    "\n",
    "\n",
    "    logging.info(f\"Total score: {total_score}\")\n",
    "\n",
    "\n",
    "    \n",
    "# if __name__ == \"__main__\":\n",
    "    \n",
    "\n",
    "#     seeds =  [3329, 4201, 8761, 2311, 2663, 4507, 6247, 2281, 4363, 5693]\n",
    "    \n",
    "#     processes = []\n",
    "#     for seed in seeds:\n",
    "#         p = multiprocessing.Process(target=solve_seed, \n",
    "#                                     args=(seed,), \n",
    "#                                     name=f\"Solving Seed-{seed}\")\n",
    "#         processes.append(p)\n",
    "#         p.start()\n",
    "    \n",
    "#     for p in processes:\n",
    "#         p.join()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "demand, df_datacenters, df_servers, df_selling_prices = load_problem_data()\n",
    "solution = Solution(df_servers=df_servers, \n",
    "                    df_data_centers=df_datacenters, \n",
    "                    df_selling_prices=df_selling_prices,\n",
    "                    verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "seed = 3329\n",
    "np.random.seed(seed)\n",
    "actual_demand = get_actual_demand(demand)\n",
    "solution.load_checkpoint(\"output_13v2/3329.pkl\", demand=actual_demand)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_solution = pd.DataFrame(solution.solution)\n",
    "df_history = pd.DataFrame(solution.historical_server_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>solution_action</th>\n",
       "      <th>server_id</th>\n",
       "      <th>action_string</th>\n",
       "      <th>buy_time_step</th>\n",
       "      <th>new_solution_obj</th>\n",
       "      <th>obj_gain</th>\n",
       "      <th>merge_with</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>add</td>\n",
       "      <td>d3917090-7783-4173-b52d-8ff9c8e674b9</td>\n",
       "      <td>GPU.S3|buy-dismiss|DC3,1.0-72</td>\n",
       "      <td>97.0</td>\n",
       "      <td>3.758413e+05</td>\n",
       "      <td>375841.311040</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>add</td>\n",
       "      <td>48d79487-7bf9-429b-8d1c-c97aed135b33</td>\n",
       "      <td>GPU.S3|buy-dismiss|DC3,1.0-72</td>\n",
       "      <td>97.0</td>\n",
       "      <td>7.516826e+05</td>\n",
       "      <td>375841.311040</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>add</td>\n",
       "      <td>532b16b9-0d0a-424e-b9d9-e030de0b7116</td>\n",
       "      <td>GPU.S3|buy-dismiss|DC3,1.0-72</td>\n",
       "      <td>97.0</td>\n",
       "      <td>1.201436e+06</td>\n",
       "      <td>449753.811040</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>add</td>\n",
       "      <td>517ab53a-fbfc-4227-bc1c-fb5e8d6b74b3</td>\n",
       "      <td>GPU.S3|buy-dismiss|DC3,1.0-72</td>\n",
       "      <td>97.0</td>\n",
       "      <td>1.577278e+06</td>\n",
       "      <td>375841.311040</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>add</td>\n",
       "      <td>642446e8-13f1-4e46-94cd-29132c258f81</td>\n",
       "      <td>GPU.S3|buy-dismiss|DC3,1.0-72</td>\n",
       "      <td>97.0</td>\n",
       "      <td>2.027032e+06</td>\n",
       "      <td>449753.811040</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92169</th>\n",
       "      <td>remove</td>\n",
       "      <td>e24272e4-18c4-4cb1-b3d7-2ce6c6467ba9</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.477575e+08</td>\n",
       "      <td>40.843896</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92170</th>\n",
       "      <td>remove</td>\n",
       "      <td>e25e83af-3626-4d0d-8f27-b828ff3d4dca</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.477575e+08</td>\n",
       "      <td>30.412288</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92171</th>\n",
       "      <td>remove</td>\n",
       "      <td>ee2b8522-d1bc-452a-9e36-8ff37721b65d</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.477575e+08</td>\n",
       "      <td>21.419924</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92172</th>\n",
       "      <td>remove</td>\n",
       "      <td>f1d782e2-9559-4c47-9e17-133915a5e4b9</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.477575e+08</td>\n",
       "      <td>21.377984</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92173</th>\n",
       "      <td>remove</td>\n",
       "      <td>fac9db7e-5d13-4f94-b927-9182b41b4ad5</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.477576e+08</td>\n",
       "      <td>38.041929</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>92174 rows  7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      solution_action                             server_id  \\\n",
       "0                 add  d3917090-7783-4173-b52d-8ff9c8e674b9   \n",
       "1                 add  48d79487-7bf9-429b-8d1c-c97aed135b33   \n",
       "2                 add  532b16b9-0d0a-424e-b9d9-e030de0b7116   \n",
       "3                 add  517ab53a-fbfc-4227-bc1c-fb5e8d6b74b3   \n",
       "4                 add  642446e8-13f1-4e46-94cd-29132c258f81   \n",
       "...               ...                                   ...   \n",
       "92169          remove  e24272e4-18c4-4cb1-b3d7-2ce6c6467ba9   \n",
       "92170          remove  e25e83af-3626-4d0d-8f27-b828ff3d4dca   \n",
       "92171          remove  ee2b8522-d1bc-452a-9e36-8ff37721b65d   \n",
       "92172          remove  f1d782e2-9559-4c47-9e17-133915a5e4b9   \n",
       "92173          remove  fac9db7e-5d13-4f94-b927-9182b41b4ad5   \n",
       "\n",
       "                       action_string  buy_time_step  new_solution_obj  \\\n",
       "0      GPU.S3|buy-dismiss|DC3,1.0-72           97.0      3.758413e+05   \n",
       "1      GPU.S3|buy-dismiss|DC3,1.0-72           97.0      7.516826e+05   \n",
       "2      GPU.S3|buy-dismiss|DC3,1.0-72           97.0      1.201436e+06   \n",
       "3      GPU.S3|buy-dismiss|DC3,1.0-72           97.0      1.577278e+06   \n",
       "4      GPU.S3|buy-dismiss|DC3,1.0-72           97.0      2.027032e+06   \n",
       "...                              ...            ...               ...   \n",
       "92169                           None            NaN      9.477575e+08   \n",
       "92170                           None            NaN      9.477575e+08   \n",
       "92171                           None            NaN      9.477575e+08   \n",
       "92172                           None            NaN      9.477575e+08   \n",
       "92173                           None            NaN      9.477576e+08   \n",
       "\n",
       "            obj_gain merge_with  \n",
       "0      375841.311040       None  \n",
       "1      375841.311040       None  \n",
       "2      449753.811040       None  \n",
       "3      375841.311040       None  \n",
       "4      449753.811040       None  \n",
       "...              ...        ...  \n",
       "92169      40.843896       None  \n",
       "92170      30.412288       None  \n",
       "92171      21.419924       None  \n",
       "92172      21.377984       None  \n",
       "92173      38.041929       None  \n",
       "\n",
       "[92174 rows x 7 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_history"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "huawei-2024-venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
